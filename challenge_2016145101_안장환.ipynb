{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "challenge_2016145101_안장환.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "w81APM0rpasp",
        "vGTaJQqjpe9Z",
        "wqd3l-ixN7qs",
        "QIeh69nzQKtS",
        "Cp72Zn3C2p_n"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janghwan0113/spine-classification/blob/main/challenge_2016145101_%EC%95%88%EC%9E%A5%ED%99%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "vDXsKayAN_LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejfEjuVvN-gs",
        "outputId": "0bc4b311-4888-4cde-f082-aa47a0fe7f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 13 17:21:06 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P0    38W / 250W |  14533MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UYhKaIZpgLm",
        "outputId": "af952936-ba10-42d2-a241-0974cfba9354"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AkmTaZIVR5s",
        "outputId": "797726dc-c815-4270-bccd-dcba99e0540d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.7/dist-packages (2.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import scipy.io\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms, datasets\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "zEC6ylxpprOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data check"
      ],
      "metadata": {
        "id": "Y-PWfzpReXrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## view_input_dcm_data"
      ],
      "metadata": {
        "id": "w81APM0rpasp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/train/img/002.dcm'\n",
        "images = sitk.ReadImage(filename)\n",
        "\n",
        "print(\"Width: \",images.GetWidth())\n",
        "print(\"Heigh: \",images.GetHeight())\n",
        "print(\"Depth: \",images.GetDepth())\n",
        "print(\"Dimension: \",images.GetDimension())\n",
        "print(\"Pixel ID:\",images.GetPixelIDValue())\n",
        "print(\"Pixel ID Type: \",images.GetPixelIDTypeAsString())\n",
        "\n",
        "images_array=sitk.GetArrayFromImage(images).astype('float32')\n",
        "img=np.squeeze(images_array)\n",
        "copy_img=img.copy()\n",
        "min=np.min(copy_img)\n",
        "max=np.max(copy_img)\n",
        "\n",
        "\n",
        "#0~1(실수)로 normalize하고 0~255(정수)로 바꿔줌\n",
        "copy_img1=copy_img-np.min(copy_img)\n",
        "copy_img=copy_img1/np.max(copy_img1)\n",
        "# copy_img*=2**8-1\n",
        "# copy_img=copy_img.astype(np.uint8)\n",
        "\n",
        "copy_img=np.expand_dims(copy_img,axis=-1)\n",
        "copy_img=cv2.cvtColor(copy_img,cv2.COLOR_GRAY2RGB)\n",
        "print(\"check\")\n",
        "\n",
        "# plt.imshow(copy_img, cmap=plt.cm.bone)\n",
        "#cv2_imshow(copy_img)\n",
        "#cv2.waitKey(0)\n",
        "#cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "plt.imshow(copy_img.squeeze(), cmap='gray')\n",
        "\n",
        "print(copy_img)\n",
        "print(copy_img.shape)\n",
        "#datatype = np.ndarray\n",
        "print(\"==================\")\n",
        "print(\"images_array\")\n",
        "print(type(images_array[0][0][0]))\n",
        "print(images_array.shape)\n",
        "print(images_array)\n",
        "print(np.amin(copy_img))\n",
        "print(np.amax(copy_img))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOLtpeMSpeF9",
        "outputId": "c5d8ae1c-90b4-4ab5-f32c-8e8165c82ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Width:  2588\n",
            "Heigh:  3232\n",
            "Depth:  1\n",
            "Dimension:  3\n",
            "Pixel ID: 3\n",
            "Pixel ID Type:  16-bit unsigned integer\n",
            "check\n",
            "[[[0.06028708 0.06028708 0.06028708]\n",
            "  [0.06124402 0.06124402 0.06124402]\n",
            "  [0.05845295 0.05845295 0.05845295]\n",
            "  ...\n",
            "  [0.11331739 0.11331739 0.11331739]\n",
            "  [0.12025518 0.12025518 0.12025518]\n",
            "  [0.12185008 0.12185008 0.12185008]]\n",
            "\n",
            " [[0.06371611 0.06371611 0.06371611]\n",
            "  [0.06204147 0.06204147 0.06204147]\n",
            "  [0.05813397 0.05813397 0.05813397]\n",
            "  ...\n",
            "  [0.11307815 0.11307815 0.11307815]\n",
            "  [0.12001595 0.12001595 0.12001595]\n",
            "  [0.12623605 0.12623605 0.12623605]]\n",
            "\n",
            " [[0.06371611 0.06371611 0.06371611]\n",
            "  [0.06052632 0.06052632 0.06052632]\n",
            "  [0.0585327  0.0585327  0.0585327 ]\n",
            "  ...\n",
            "  [0.11347687 0.11347687 0.11347687]\n",
            "  [0.11738437 0.11738437 0.11738437]\n",
            "  [0.12519936 0.12519936 0.12519936]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.14824562 0.14824562 0.14824562]\n",
            "  [0.14338118 0.14338118 0.14338118]\n",
            "  [0.13883573 0.13883573 0.13883573]\n",
            "  ...\n",
            "  [0.13269538 0.13269538 0.13269538]\n",
            "  [0.1299043  0.1299043  0.1299043 ]\n",
            "  [0.13030303 0.13030303 0.13030303]]\n",
            "\n",
            " [[0.13716109 0.13716109 0.13716109]\n",
            "  [0.13700159 0.13700159 0.13700159]\n",
            "  [0.13030303 0.13030303 0.13030303]\n",
            "  ...\n",
            "  [0.13437001 0.13437001 0.13437001]\n",
            "  [0.13413078 0.13413078 0.13413078]\n",
            "  [0.12998405 0.12998405 0.12998405]]\n",
            "\n",
            " [[0.12767145 0.12767145 0.12767145]\n",
            "  [0.13046253 0.13046253 0.13046253]\n",
            "  [0.12663476 0.12663476 0.12663476]\n",
            "  ...\n",
            "  [0.13524722 0.13524722 0.13524722]\n",
            "  [0.13787879 0.13787879 0.13787879]\n",
            "  [0.13556619 0.13556619 0.13556619]]]\n",
            "(3232, 2588, 3)\n",
            "==================\n",
            "images_array\n",
            "<class 'numpy.float32'>\n",
            "(1, 3232, 2588)\n",
            "[[[3067. 3079. 3044. ... 3732. 3819. 3839.]\n",
            "  [3110. 3089. 3040. ... 3729. 3816. 3894.]\n",
            "  [3110. 3070. 3045. ... 3734. 3783. 3881.]\n",
            "  ...\n",
            "  [4170. 4109. 4052. ... 3975. 3940. 3945.]\n",
            "  [4031. 4029. 3945. ... 3996. 3993. 3941.]\n",
            "  [3912. 3947. 3899. ... 4007. 4040. 4011.]]]\n",
            "0.0\n",
            "1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## view_label_mat_data"
      ],
      "metadata": {
        "id": "vGTaJQqjpe9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mat_file_name =  \"/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/train/label/002.mat\"\n",
        "mat_file = scipy.io.loadmat(mat_file_name)\n",
        "\n",
        "print(type(mat_file))\n",
        "\n",
        "for i in mat_file:\n",
        "    print(i)\n",
        "\n",
        "mat_file_value = mat_file['label_separated']\n",
        "print(\"size :\",mat_file_value.shape)\n",
        "print(\"datatype:\", type(mat_file_value[0][0][0]))\n",
        "\n",
        "print(mat_file_value[:,:,6])\n",
        "plt.imshow(mat_file_value[:,:,6],cmap='gray')#plt.cm.bone\n",
        "mat_file_value[:,:,6] = mat_file_value[:,:,6]*(-1)\n",
        "#datatype = np.ndarray\n",
        "print(\"==================\")\n",
        "print(mat_file_value[:,:,6])\n",
        "print(\"mat_file_value\")\n",
        "print(np.amin(mat_file_value[:,:,6]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx5Les7Aphc9",
        "outputId": "a236b326-6949-4f73-83e5-ccec40236483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "__header__\n",
            "__version__\n",
            "__globals__\n",
            "label_separated\n",
            "size : (3232, 2588, 7)\n",
            "datatype: <class 'numpy.uint8'>\n",
            "[[1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " ...\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]]\n",
            "==================\n",
            "[[255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " ...\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]]\n",
            "mat_file_value\n",
            "0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNet Network"
      ],
      "metadata": {
        "id": "2jJv_N7wRhSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/datasets'\n",
        "ckpt_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/checkpoint'\n",
        "log_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/log'\n",
        "result_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/result'\n",
        "board_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/leaderboard'\n",
        "test_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/test'"
      ],
      "metadata": {
        "id": "DGCUTmJ7SF2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "## U-Net 구조 설계\n",
        "class UNET(nn.Module):\n",
        "\n",
        "    # U-Net에서 활용할 기본 block 들을 정의합니다. \n",
        "    def __init__(\n",
        "            self, in_channels=1, out_channels=6, features=[64, 128, 256, 512],\n",
        "    ):\n",
        "        super(UNET, self).__init__()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Contractive Path에 필요한 모듈을 self.downs 리스트에 보관합니다. DoubleConv blocks.\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Expansive Path에 필요한 모듈을 self.ups 리스트에 보관합니다. Transpose2d Convolution 및 DoubleConv blocks.\n",
        "        for feature in reversed(features): #[512, 256, 128, 64]\n",
        "            self.ups.append(\n",
        "                nn.ConvTranspose2d(\n",
        "                    feature*2, feature, kernel_size=2, stride=2,\n",
        "                )\n",
        "            )\n",
        "            self.ups.append(DoubleConv(feature*2, feature))\n",
        "            \n",
        "        #self.up : [(ConvTransposed2d, DoubleConv) *4]\n",
        "\n",
        "\n",
        "        # U-Net의 가장 아래 부분.\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "\n",
        "        # 가장 마지막 Convolution layer. 1x1 Conv. 로 Output channel 을 맞추는 역할. \n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    # __init__ 에서 정의한 요소들로 실제 U-Net을 설계.\n",
        "    def forward(self, x):\n",
        "\n",
        "        # skip-connection 시킬 feature map 들을 보관하고 있을 리스트.\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs: #self.downs: (DoubleConv *4)\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]  #순서 뒤집어줌\n",
        "\n",
        "        ## self.ups: [(ConvTranspose2D, DoubleConv) x 4]\n",
        "        for idx in range(0, len(self.ups), 2): ## idx: 0, 2, 4, 6\n",
        "\n",
        "            # ConvTransposed2d\n",
        "            x = self.ups[idx](x) \n",
        "            skip_connection = skip_connections[idx//2] ## idx//2: 0, 1, 2, 3\n",
        "\n",
        "            # Resize the upsampled feature map to the size of the skip-connected feature map.\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            \n",
        "            # DoubleConv\n",
        "            x = self.ups[idx+1](concat_skip) ## idx+1: 1, 3, 5, 7\n",
        "\n",
        "        return self.final_conv(x)"
      ],
      "metadata": {
        "id": "f9edEHIg0Kbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 기본 제목 텍스트\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        \n",
        "        #Convolution, Batch norm, ReLU set\n",
        "        def CBR2d(in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, bias = True):\n",
        "            #convolution layer\n",
        "            layers = []\n",
        "            layers += [nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, stride = stride, padding = padding, bias = bias)]\n",
        "            #batch norm layer\n",
        "            layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
        "            #ReLU layer\n",
        "            layers += [nn.ReLU()]\n",
        "\n",
        "            cbr = nn.Sequential(*layers)\n",
        "            \n",
        "            return cbr\n",
        "        \n",
        "        #contracting path\n",
        "        self.enc1_1 = CBR2d(in_channels = 1, out_channels = c_a[0] )\n",
        "        self.enc1_2 = CBR2d(in_channels = c_a[0], out_channels = c_a[0])\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size = 2)\n",
        "\n",
        "        self.enc2_1 = CBR2d(in_channels = c_a[0], out_channels = c_a[1])\n",
        "        self.enc2_2 = CBR2d(in_channels = c_a[1], out_channels = c_a[1])\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size = 2)\n",
        "\n",
        "        self.enc3_1 = CBR2d(in_channels = c_a[1] , out_channels = c_a[2])\n",
        "        self.enc3_2 = CBR2d(in_channels = c_a[2], out_channels = c_a[2])\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size = 2)\n",
        "\n",
        "        self.enc4_1 = CBR2d(in_channels = c_a[2], out_channels = c_a[3])\n",
        "        self.enc4_2 = CBR2d(in_channels = c_a[3], out_channels = c_a[3])\n",
        "\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size = 2)\n",
        "\n",
        "        self.enc5_1 = CBR2d(in_channels = c_a[3], out_channels = c_a[4])\n",
        "\n",
        "        #expansive path\n",
        "        self.dec5_1 = CBR2d(in_channels= c_a[4] , out_channels = c_a[3])\n",
        "\n",
        "        self.unpool4 = nn.ConvTranspose2d(in_channels= c_a[3], out_channels = c_a[3] , kernel_size=2 , stride= 2, padding =0 , bias = True)\n",
        "\n",
        "        self.dec4_2 = CBR2d(in_channels= c_a[3]*2 , out_channels = c_a[3])\n",
        "        self.dec4_1 = CBR2d(in_channels= c_a[3] , out_channels = c_a[2])\n",
        "\n",
        "        self.unpool3 = nn.ConvTranspose2d(in_channels = c_a[2] , out_channels = c_a[2] , kernel_size=2 , stride=2 , padding =0 , bias = True)\n",
        "\n",
        "        self.dec3_2 = CBR2d(in_channels= c_a[2]*2 , out_channels = c_a[2])\n",
        "        self.dec3_1 = CBR2d(in_channels= c_a[2], out_channels = c_a[1])\n",
        "\n",
        "        self.unpool2 = nn.ConvTranspose2d(in_channels= c_a[1], out_channels=c_a[1] , kernel_size=2 , stride=2 , padding =0 , bias = True)\n",
        "\n",
        "        self.dec2_2 = CBR2d(in_channels=2*c_a[1] , out_channels = c_a[1])\n",
        "        self.dec2_1 = CBR2d(in_channels= c_a[1], out_channels=c_a[0])\n",
        "\n",
        "        self.unpool1 = nn.ConvTranspose2d(in_channels= c_a[0], out_channels=c_a[0] , kernel_size=2 , stride=2 , padding = 0, bias = True)\n",
        "\n",
        "        self.dec1_2 = CBR2d(in_channels= 2*c_a[0], out_channels = c_a[0])\n",
        "        self.dec1_1 = CBR2d(in_channels= c_a[0], out_channels= c_a[0])\n",
        "\n",
        "        self.fc = nn.Conv2d(in_channels= c_a[0], out_channels= 6, kernel_size=1 , stride=1 , padding =0 , bias = True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        enc1_1 = self.enc1_1(x)\n",
        "        enc1_2 = self.enc1_2(enc1_1)\n",
        "        pool1 = self.pool1(enc1_2)\n",
        "\n",
        "        enc2_1 = self.enc2_1(pool1)\n",
        "        enc2_2 = self.enc2_2(enc2_1)\n",
        "        pool2 = self.pool2(enc2_2)\n",
        "        \n",
        "        enc3_1 = self.enc3_1(pool2)\n",
        "        enc3_2 = self.enc3_2(enc3_1)\n",
        "        pool3 = self.pool3(enc3_2)\n",
        "        \n",
        "        enc4_1 = self.enc4_1(pool3)\n",
        "        enc4_2 = self.enc4_2(enc4_1)\n",
        "        pool4 = self.pool4(enc4_2)\n",
        "\n",
        "        enc5_1 = self.enc5_1(pool4)\n",
        "\n",
        "        dec5_1 = self.dec5_1(enc5_1)\n",
        "\n",
        "        unpool4 = self.unpool4(dec5_1)\n",
        "        \n",
        "        cat4 = torch.cat((unpool4, enc4_2), dim=1)\n",
        "        \n",
        "        dec4_2 = self.dec4_2(cat4)\n",
        "        dec4_1 = self.dec4_1(dec4_2)\n",
        "        \n",
        "        unpool3 = self.unpool3(dec4_1)\n",
        "        cat3 = torch.cat((unpool3, enc3_2), dim=1)\n",
        "        dec3_2 = self.dec3_2(cat3)\n",
        "        dec3_1 = self.dec3_1(dec3_2)\n",
        "\n",
        "        unpool2 = self.unpool2(dec3_1)\n",
        "        cat2 = torch.cat((unpool2, enc2_2), dim=1)\n",
        "        dec2_2 = self.dec2_2(cat2)\n",
        "        dec2_1 = self.dec2_1(dec2_2)\n",
        "        \n",
        "        unpool1 = self.unpool1(dec2_1)\n",
        "        cat1 = torch.cat((unpool1, enc1_2), dim=1)\n",
        "        dec1_2 = self.dec1_2(cat1)\n",
        "        dec1_1 = self.dec1_1(dec1_2)\n",
        "        \n",
        "        x = self.fc(dec1_1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "fpQPDaFOSki0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "wpRQ1E8ijtrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir, transform = None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        if self.data_dir == '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/test':\n",
        "            lst_input = os.listdir(os.path.join(self.data_dir,'img'))\n",
        "            lst_label = os.listdir(os.path.join(self.data_dir, 'img'))\n",
        "\n",
        "            lst_input.sort()\n",
        "            lst_label.sort()\n",
        "\n",
        "            self.lst_input = lst_input\n",
        "            self.lst_label = lst_label\n",
        "        else:\n",
        "            lst_input = os.listdir(os.path.join(self.data_dir,'img'))\n",
        "            lst_label = os.listdir(os.path.join(self.data_dir, 'label'))\n",
        "\n",
        "            lst_input.sort()\n",
        "            lst_label.sort()\n",
        "\n",
        "            self.lst_input = lst_input\n",
        "            self.lst_label = lst_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lst_label)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        #testset 일 경우\n",
        "        if self.data_dir == '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/test':\n",
        "            #label은 없어야하지만 dataset을 구성해주기 위해 input을 복사해주어 structure만 만들어줌.\n",
        "            \n",
        "            #absolute path of img and label\n",
        "            input_abs_path = os.path.join(*[self.data_dir, 'img', self.lst_input[index]])\n",
        "            label_abs_path = os.path.join(*[self.data_dir, 'img', self.lst_input[index]])\n",
        "            \n",
        "           #np.ndarray of img\n",
        "            images = sitk.ReadImage(input_abs_path)\n",
        "            input_np =sitk.GetArrayFromImage(images).astype('float32')\n",
        "            input_np_copy = input_np.copy()\n",
        "\n",
        "            #input array를 0~1 float 로 바꿔줌\n",
        "            input_np_copy1 = input_np_copy - np.min(input_np_copy)\n",
        "            input_np_copy = input_np_copy1 / np.max(input_np_copy1)\n",
        "\n",
        "            #false np.darray of label            \n",
        "            label_np =sitk.GetArrayFromImage(images).astype('float32')\n",
        "\n",
        "            \n",
        "            data = {'input' : input_np_copy, 'label' : label_np}\n",
        "\n",
        "            if self.transform:\n",
        "                data = self.transform(data)\n",
        "\n",
        "            return data \n",
        "\n",
        "        #train, validation set 일 경우\n",
        "        else:\n",
        "        \n",
        "            #absolute path of img and label\n",
        "            input_abs_path = os.path.join(*[self.data_dir, 'img', self.lst_input[index]])\n",
        "            label_abs_path = os.path.join(*[self.data_dir, 'label', self.lst_label[index]])\n",
        "            \n",
        "            #np.ndarray of img and label\n",
        "            images = sitk.ReadImage(input_abs_path)\n",
        "            input_np =sitk.GetArrayFromImage(images).astype('float32')\n",
        "            input_np_copy = input_np.copy()\n",
        "\n",
        "            #input array를 0~1 float 로 바꿔줌\n",
        "            input_np_copy1 = input_np_copy - np.min(input_np_copy)\n",
        "            input_np_copy = input_np_copy1 / np.max(input_np_copy1)\n",
        "\n",
        "            #label numpy array\n",
        "            label_mat_file = scipy.io.loadmat(label_abs_path)\n",
        "            label_np = label_mat_file['label_separated']\n",
        "\n",
        "            label = label_np.transpose(2,0,1)[:6,:,:].copy()\n",
        "            # label[6] = -label[6]+1\n",
        "\n",
        "            #data['input'] = 0~1 float32 , data['label'] = 0~1 float32\n",
        "            data = {'input' : input_np_copy, 'label' : label.astype('float32')}\n",
        "\n",
        "            if self.transform:\n",
        "                data = self.transform(data)\n",
        "\n",
        "            return data        "
      ],
      "metadata": {
        "id": "lPn8czK0jwpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset example"
      ],
      "metadata": {
        "id": "wqd3l-ixN7qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3zFlIxlx3hMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = Dataset(data_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/train')\n",
        "\n",
        "# print(example.lst_input)\n",
        "# for name in example.lst_input:\n",
        "#     print(name[:-3])\n",
        "#     break\n",
        "# print(example.lst_input.pop(0)[:-3])\n",
        "\n",
        "data = example.__getitem__(1)\n",
        "\n",
        "input = data['input']\n",
        "label = data['label']\n",
        "\n",
        "# input = cv2.resize(input.transpose(1,2,0), (2048,2048)) \n",
        "# label = cv2.resize(label.transpose(1,2,0), (2048,2048)) \n",
        "\n",
        "# print(input.shape)\n",
        "# print(input[0])\n",
        "# print(label.shape)\n",
        "# print(label[6])\n",
        "# print(type(np.amax(label[6])))\n",
        "# print(type(np.amax(input[0])))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(input.transpose(2,0,1).shape)\n",
        "# print(input.transpose(1,2,0).shape)\n",
        "# plt.imshow(input.transpose(2,0,1), cmap='gray')\n",
        "\n",
        "\n",
        "plt.subplot(151)\n",
        "plt.imshow(input.squeeze(), cmap='gray')\n",
        "\n",
        "plt.subplot(152)\n",
        "plt.imshow(label[0], cmap='gray')\n",
        "plt.subplot(153)\n",
        "plt.imshow(label[3], cmap='gray')\n",
        "plt.subplot(154)\n",
        "plt.imshow(label[4], cmap='gray')\n",
        "plt.subplot(155)\n",
        "plt.imshow(label[6], cmap='gray')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "AcAc07eDvGCO",
        "outputId": "29919ac3-5a14-4166-be0b-f5eca8b149cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-966677d21228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m155\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 6"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3da4ykV33n8e+/nrpXX8Y9N8b2rA1kEjOwEPAIkACtsUNi+4W9LxBipCQEmZ19AatkN7sSm13CZd/sbrQXRbAsg2IBEYb1JkFrISMLyODIyCDaG8cwNnZmBxOPMXjMTPf0pe519kXXOfNUdXVP90xX1VP9/D5Sa7qeeqrq1HH7/J/nXP7HnHOIiEj6ZMZdABERGQ8FABGRlFIAEBFJKQUAEZGUUgAQEUkpBQARkZRSABCRRDKz+83sZTP70QbPm5n9qZmdMbOnzOwtoy7jpFMAEJGk+gJw5ybP3wUc6f6cAD47gjLtKgoAIpJIzrm/AS5scsq9wJfcmu8Be8zs0GhKtztkx10AEZGrdAPwQuzxue6xl+InmdkJ1u4QqFQqt95yyy0jK+C4PPHEE6845/Zf6TwFABHZ1ZxzJ4GTAMeOHXPz8/NjLtHwmdlPt3KeuoBEZFK9CByOPb6xe0y2SAFARCbVQ8DvdmcDvR1YdM69dKUXyWXqAhKRRDKzrwC3AfvM7BzwcSAH4Jz7n8DDwN3AGWAV+OB4Sjq5FABEJJGcc8ev8LwDPjyi4uxK6gISEUkpBQARkZRSABARSSkFABGRlFIAEBFJKQUAEZGUUgAQEUkpBQARkZRSABARSSkFABGRlFIAEBFJKQUAEZGUUgAQEUkpBQARkZRSABARSSkFABGRlFIAEBFJKQUAEZGUUgAQEUkpBQARkZRSABARSSkFABGRlFIAEBFJKQUAEZGUUgAQEUkpBQARkZRSABARSSkFABGRlFIAEBFJKQUAEZGUUgAQEUkpBQARkZRSABARSSkFABGRlFIAEBFJKQUAEUkkM7vTzJ41szNm9tEBz/8jMztlZn9rZk+Z2d3jKOckUwAQkcQxswj4DHAXcBQ4bmZH+07798CDzrk3A+8H/sdoSzn5FABEJIneCpxxzp11zjWArwL39p3jgJnu77PAz0ZYvl1BAUBEkugG4IXY43PdY3GfAH7bzM4BDwP/YtAbmdkJM5s3s/nz588Po6wTSwFARCbVceALzrkbgbuBPzezdW2ac+6kc+6Yc+7Y/v37R17IJFMAEJEkehE4HHt8Y/dY3H3AgwDOuceBIrBvJKXbJRQARCSJfgAcMbNXm1metUHeh/rO+QfgDgAzex1rAUB9PNugACAiieOcawEfAR4BnmFtts9pM/uUmd3TPe0PgX9mZn8HfAX4PeecG0+JJ1N23AUQERnEOfcwa4O78WN/HPv9aeAdoy7XbqI7ABGRlFIAEBFJKQUAEZGUUgAQEUkpBQARkZRSABARSSkFABGRlFIAEBFJKQUAEZGUUgAQEUkpBQARkZRSABARSSkFABGRlFIAEBFJKQUAEZGUUgAQEUkpBQARkZRSABARSSkFABGRlFIAEBFJqZEHADO708yeNbMzZvbRUX9+EqlO1lOdDKZ6kZ000gBgZhHwGeAu4Chw3MyOjrIMSaM6WU91MpjqRXbaqO8A3gqccc6ddc41gK8C9464DEmjOllPdTKY6kV2VHbEn3cD8ELs8TngbfETzOwEcKL78NZsNuuP0+l01r2hmfX8m8lkMDOccz3n+Nd3Oh2cc2QyGZxz4T39+dlsNpzjj2/2uVvVXx7/byaTodPp1GKnrquT7rk99bKtDwduvbX3Je12m3q9jnOOH//4x9t9u1EbSp1MqE3/VlJaJ6845/aPuxCTaNQB4IqccyeBkwC5XM4dOHCAZrMZGkv/r2/E8/k8uVyOdrsNQLlcDg19JpOh1WrRarXwgQRgdXWVXC5HLpfjwoULrKyskM1mKRaLlEolLl26RBRF1Go16vU67XY7fJ633QDQ/W4454iiiCiKyOVyAFy6dGl5O/ViZu4Kp/d44IEHOH78+MDnXn75ZQ4ePLidt0uMa6mTCbbp30pK6+Sn4y7ApBp1AHgROBx7fGP32EBmRhRFIQB0Oh2y2SzZbJapqSlyuRyZTIZ2u02r1SKXy9FqtYDLV/K+4XfOheBRLBbD+xQKBarVKlEUUalUWFpaIpvNUq/XaTab4Q4g3vjvFOecL19+q3VyNd73vveF79/vDW94w05+1LDseJ1MsKH+rUi6jHoM4AfAETN7tZnlgfcDD13pRd1uEjKZDLlcLjTq2Ww2XJ0DdDodCoUC2Ww2NPb+yj7e7eLfq9PpEEVRCAS1Wq0noPgr9qu52t+Mf1+AKIoAitutk+247bbbuOeee3j00UfXdWedP39+Jz9qRw2zTibYUP9WJF1GGgCccy3gI8AjwDPAg86505u9ptPpYGYUCgXK5XK4evd3Bv6qP5fL0el0qNfr4Sq/WCzinKPZbAKhsQ3dO9VqlcXFRQDy+Xz4PN/4d8u8rkw7FRBi7/0PbKNOtuuxxx7j61//Orfffjt33HEHjz/+OADPP//8Tn7MMAytTibYUP9WJF1GPgbgnHsYeHir5/v+8nK5HK78/dU7QLPZDH3+xWIRgFarRbVaJZPJUCgUqNfr1Go1nHNUKpXQz7+ysgJAqVQKgcLfUfiuH38HsNN3AX3vt+icO7ajHzBAp9PhO9/5Du9617v40Ic+xAMPPDDsj7wmzrlfHXcZEmgkfyuSDokbBO7nZ/TEZ+vEu3BarRb5fJ5OpxPGCgqFQhgUXl1dpdlskslkQj/+wsICtVoNM6NcLgNQq9VCIInPFhrG9/HfI94VNErtdpvPfe5zI/9cEUmWxAcAP1DqG/soisKMHN9Q+66gdrtNFEXU6/WegVsz6xkHKBQKYYA3k8nQaDR6GuRhN87x9x5HABARgQnJBeSne/ppnX6QFgiDuP4K3/ff+6miURSFGUP+Nf6xmVGv10Ng6L/63+nun/jV/053KYmIbFeiA0D8Krler4fG3x9bWFgIz9VqNRqNBu12m3a7He4YWq0Wy8vLFItFoigik8lQrVZxztFoNABC95Jv+Act/PJ2egBYgUBExiXxXUCdTic07n7xFsDKygqdTod2ux2mffqr9lqtRjabpdVqUa/XqVQq1Go1ms0m1WqV5eVl2u126CLy7wOMvGtGXUAiMi6JvgPodDpUq1Xa7XaYv99ut8MArl8H0Gq16HQ65HI5pqenmZ2dBQh3DM1mMyz8WllZ6Vk74PXP/PHTT4d1ha4xAJEd83ozO21myZ7WlkCJvgMoFArA5W6S/iv9UqkUrvR9l0+1Wg2LxfxYQKvVotlshi4f/37tdjuMDfQP/A7qpx/GgjB1AYlcsx87595sZgfGXZBJk+g7gCiKOHLkSLga94O48SmdfrZPPp8nn88zPT3NzMxMCAr5fD5MC/UzgeJ9/H7qqG/8/eyiUTTMVxpvEJEtaQM4514ed0EmTaIDQD6fp1qthkbS5wbyC8L8lX2r1aLRaNBoNFhdXWVxcZFsNkulUumZ/unf079X/0Csb5DVKItMlFvM7HtmduegJ83shJnNm9l8klOfjEOiA8D+/ft5/vnnw/z+eJdQfEwg3m3j7wyWl5dptVpkMpkQJPx4gueco91u02g0wniBf79h9v/7z1b3j8iOeBY4DnzezPb0P+mcO+mcO+acO7Z/v7JGxyU6AJw9ezYMysZz9cDlwVO/ECy+ctfnCvLrAMrlcmjga7VaWAMQb4DjV/+DGuadXgsQ/w4ick2cc+4nwHPAkXEXZpIkehDYz/6By0nh/DRPzx/3g8D+sZ/775PHNZvNMHvITx3179/fBTSM1M9xuvIX2Vlmtg/4VeDsuMsySRIdAICezVz6d9UqFAoh7XN8JbBP/FatVllaWqJcLofNXfwgr0/+5q/6/eIxEZk4rwdOAf/GOffLcRdmkiQ6APgunGw2Sy6Xo9FohIFgv6WhvyvwdwF+oZjfPcybnp7uGTPwYwHxfQIGDQwP+/upG0jkmp1WhtSrk+gAAISrej+/38zCquBisdgzqOsbfT9dtFwuMz09TbvdplAoUKlUuHTpUsgT1L83r+xO73znO3nNa15DLpdjYWGBlZUVKpUKBw4c4Prrr+djH/vYuIsoMhaJDgD+qtw36tlsllKpFLJ/xvlG3y8Qm5ubI5/Ph6vs+N7A/eme43cRo6Ir/9F59NFHewJ8/L91q9VSAJDUSnQAgLXFYL6Bjg/y+gYfehdU+Wmf9XodgJmZGdrtNq+88gr1ej0khOt/HYxncFYDwsPXf3cXr/N77rln1MURSYxEB4D4HQBcTgvtB3P9WIC/ms7n8yEFRBRFFItFMpkMy8vLmFnYNjK+kngrV+LDXg8g4/ONb3xj3EUQGZuJ6Pj2DXa5XA6pHeJBIZfLhcYf1qaPXrp0iYWFhZAILh5I+nfl2ug5T4307rVv375xF0FkbBIdAPzgrJ8J5Ld+9IvCoigKKaL9hvH+fH+l71NDVyqVsCl8fNrnsFf8XomCy3h9+tOfHncRRMYm8V1AU1NTdDqdkPWzXC6zvLzM1NQUpVIJIAzwtlqtngFdf1fgt4ssFAphwZh///7Pk93n85//PG984xtxznHu3DmeeeYZnnvuOXK5HF/72tfGXbzEKRaLPYstZfdKdADwuX3y+XzPXsD+DmB1dTXk7wHClX4mk2FmZiYsAPNX/D4XkF8MBoRxhP4UDaMKBgo6w3fixIlw9xefNiy9br75Zu677z7e+9738rrXvW7cxZERSHQA8Iu+gNCtUywWQ6K3QqFALpcLA75RFIXEb51Oh0uXLoU8QH4vgEwm05MCon9BmOxOavjXe/e7380tt9zCgQMHeNOb3sR73vMepqamxl0sGaHEBwC4vBFMp9NhaWmJKIqo1+uUy+XQPeSv6H1+/3q9zvT0dMgIWiqVQkI4vwlMfOroTqWBGDSIvJXzRUbtW9/61oYLIOOr4mX3SvQgMBDm7fs5+ysrK8zOzjIzMxNSQ/h+fX+V71cNLy8vk8lkyGazTE9PMzc3R6FQ2PAPeycHhLfyPmr8ZZwee+yxDZ/75Cc/OcKSyLgkPgD4/ns/yDs1NcWBAweYmZkBCPP7fXI3PxBcqVSAtW0l/cYxcHlKqXOuJ8ncOGYD6QpLxun222/f8LkPfvCDIyyJjEuiu4CAkPfHp3fodDosLi6GnECzs7NUq9We8YLp6emwViC+3ePq6iqrq6vhmJ8q6heTjSM5m4KAjEt8XKTdbvPkk0/yxBNP8PTTT3Pq1KkxlkxGJdEBwOfs2bt3L5VKhaWlpbB7l18X4LeM9H2Z8eO5XI6lpaUwYAxrdww+DXQ8f9AwBgnVjypJ9/jjj/PEE0/w5S9/mfn5+Z4UK7L7JToAAFQqFTqdDhcvXgwNfaPRoFgsks/nWVpaCukf/HRRz+cP8pu/+IVkfuAYLm8642cZbWRYU0M1DiDjdNttt4WxM0mfRAcA3z3jV/P6q/woimg0GqEh9zl+gDAeEL8jaDQa5PP5EDSiKAoDxEAILP17AoyC7hBknNT4p1viB4HjSd387343sEqlQi6Xo1arhbGCm2++OSwai08jrdVqYVFYPGDE9wLwg8PxTeZFRHariQgA/oo+3qD7FcGFQiF051y8eJFms8nevXtDV5E/13f9+LuJ2dnZns+JJ4bzj6/Vld5D3T8iMk6JDgDxBrLT6fQEg2w2G6Z4xhez/OQnP6HRaDA9PR1WNdZqtXV7BvtEcn6dgb8T2Gw66FaCwnYCh+4wRGScEh0AgLB6d3V1lXq9Tr1eD332q6urPat4Dx06RKPRCFM+W60WpVIp3CVEUUQURWGLyVKpFFYZxzeW911BV2s700l1FyAi45LoQWAgDALD5dz/5XI5DPbmcjmazSbXXXcd1Wo1JIqDtbQQmUwmzCRaXV0Nr/NdQlNTU9Tr9ZBOIr5RzCg3iBcRGbUr3gGY2WEzO2VmT5vZaTP7/e7xOTP7ppn9ffff67rHzcz+1MzOmNlTZvaW2Ht9oHv+35vZB6702X61bj6fD7N4ZmZmmJqaIpfLUSgUiKKI2dnZMEh80003UavVwgphIGQALZfLFAoF8vl8z8BvfI2AvwPYbDaQn17abDZpNpthDUH8eKvV6hlMbrfb4fz4+3ZnYbxhq3WSJqqTgfS3IjtmK11ALeAPnXNHgbcDHzazo8BHgW87544A3+4+BrgLONL9OQF8FtYCBvBx4G3AW4GP+6CxEedcmLo5MzNDqVTqafyz2SzFYpHp6WkymQx79uwJ2z/6cQLfEPtZQL7f3zfCtVqNPXv2rBsDiI8FDNodzI8h+DsHf1fhA4/PUeRf44OZTz/tj1erVYBntlonKaM6WU9/K7JjrhgAnHMvOef+b/f3Jdb+AG8A7gW+2D3ti8A/7f5+L/Alt+Z7wB4zOwT8FvBN59wF59xF4JvAnZt9tm+EC4VC6Mv3i7ZyuRyVSiXk/PG7hvm+f994+7sAb3l5OWQE9esMlpeXQ6PdPyA86C6gfwvJ/tQS0JthND6LKT5g7aekAu2t1kmaqE4G0t+K7JhtDQKb2c3Am4HvAwedcy91n/o5cLD7+w3AC7GXnese2+j4puJpH/yVu2+845t8VCqVcPXvr7j9a+NX4/41xWIxLCLrfree7p+tJofrnz466DX9QSRexr50vFuqk5RRnQymepFrtuVBYDObAv4S+APn3KW+HbScme3InEYzO8Fa11Fo+IvFYs/CLb+yt/vZlEol6vU6APl8PswE8vl+qtVqz4pHn/bBLxDzs4UajUbPeoMrBQEfZKIouurtJbcxWyjUi6xRnaynOpHt2NIdgJnlWGv8v+yc+6vu4V90u3bo/vty9/iLwOHYy2/sHtvoeA/n3Enn3DHn3DG/xaPvWolfrfuuIH/V7ht034CvrKxQr9fDGoBKpUI+n8c5x+LiIqurq2FRmP+JN9r9YwD9DbUf2PWfHz8e/9e/V/9rN0g7MbBO+utl0PO7mOpksCv+/zOGMsmE2cosIAP+DHjGOfdfY089BPiZCB8A/k/s+O92ZwO9HVjsdhU9AvymmV3XHbz6ze6xzT6bfD5Pu92mXq/TbDZDo++7gfL5PPV6vaf7xm8U4/v1gbBhjB+M9XcU8YygvlHu7wrq5/co8EEoVGas3z8+HuC7oPxdiT/mF6YB0VbrJE1UJwPpb0V2zFa6gN4B/A7wQzN7snvsj4D/CDxoZvcBPwXe133uYeBu4AywCnwQwDl3wcz+A/CD7nmfcs5duNKH+3QOfuAX6OnPr9VqIUD4hr3ZbFIoFHqmXvpZQb4rqN1uUywWwyyhZrMZgo232VaR/q4gXhY/qOy3pfTBwQcSH2z8cT8FtVqtvq5bL1uqkxRRnaynvxXZMVcMAM65x4CNOrTvGHC+Az68wXvdD9y/nQL6hjqfz1Mul0P/fSaTCY277+v3DWq5XKZarbK4uBgacd8Axxt0HzTq9fq6GUD+NbC+Cye+xqCfz0vUf75fhdyth/BcNwD8SLfs6znnfmXcZUgg/a3Ijkl8KgjfuF9//fWYGcVikampqRAUfIMb79apVCr88pe/7Ekf7fv447l//B4B8av5za74d4pyAIlIEkxMAMhkMj25e5rNJrlcLswG8lfpfjyg0WjQbrfDlbzfEzg+cAy9G8L4dQbx94v/roZbRHaTiQgAhUIh9KsvLy+HweBqtcrS0lKYJrqystLT5++c69kbIL7rl2/UfQDwQeJqp3Neja2uNRARGYbEB4BMJsOhQ4dot9thgNY39v75xcXFsLAL1hrWqampMKjrr9z9XQBc3mfAB4t6vR7OjTfMfQu1rll/WgndVYjIuCQ6AJgZBw8eDInc/EBwp9OhWCxSLBbZt28fMzMzNBoNSqVSCAx79uwJs278AHA8D5Cflum7ifoXgPWXQ1fqIrLbJDoA5HI5brrpptBAT09Pc+DAAQ4dOsThw4cpl8s0Go0wyFssFgFYWVlhdna254rfL/aqVqvhTiKe76d/5g8MHgfwrvXKfTvpJkRkU3vMzJmZZkdtU6L3A/BdPZVKJez7W6vVmJub4+LFixSLRZxzYa2A71KJ9+v74OG7dnzjHx8g9l1B8SRy3gYrdkUkOQ6ylp9MtinRAQDWVupevHiRXC5HLpfj8OHDLC0t9TT6PiOoTwbnF4bFc/T4bqD4qly4vBG87//vT+42DMN+f5GU+TlQG3chJlGiu4D8rB/f+Hc6HfL5fFi122w2yWazLCwsMDU1RSaTCesDoiiiVCqFxVedTqdnk/jNBmP7Et2FYzt1FxB/LwUCkWu2uNmTZnbCzObNbP78+fOjKtNESHQA8MnWVlZWWFhYoN1uc+nSJWZnZykWi1QqFVqtFvl8Ptwl+ORx7XabKIqo1+thHYGfJdTf9+/F0zTHg0L/7ztBYwAioxFPkLd///5xFydREh0A/BRPv41irVbjF7/4Ba997WtDY10ul6lUKmEWkN/sBQg7dgGhOyie+bNQKPR0B8Vtls3zWm02uCwi2/aPWdut8CENBG9PoscAfKO/d+/e0HUDa4350tISAIcOHaLRaPRM+/Tn+it//15x/Smc41fkm83P36kGW4PLIjvmh8Ay8K+dc/PjLswkSXQAaDQaIaunXwvgnOP06dPMzc3RbrdZWVkJm7L4aZ/xQVafSsIPGPv3BXrGAgb1+/vf1UiLyG6U6C4gv7HLxYsXWVpaClf4jUYjDPp2Oh3m5uYAQpeOX/DlN473s4T8DCDfBRSfLrrZT7w810IDvyLD4Zy7TVf/25f4AODn8ccXg/3sZz9jdnaWXC5HsVgkl8vRbDbZv38/mUyGqampMHPI3w34RG/x3cXiU0SvNAtopwzaH1hEZBwSHwB8jv+ZmRny+Txzc3N0Oh2mp6dD5s9Wq8V1111HqVSiUCgQRRF79uzpWQfgVwvHp4X64/0pIOIpoYeVCVQNv4iMW6IDQBRF7N27N2Tq9DN4pqamqNVq1Ot1KpUKpVKJXC5Ho9EIs3pWV1fDHYDP8++zgwLhcbxh9+MFg+4AhjEOoGmgIjJOiQ4AnU6H5eXlsGnLz3/+c+bm5igWi6EbZ2FhATOjVCpRq9UoFos0Gg1WV1fDVb9/r3a7HWYIxa/8gbBHQP8A8DBoGqiIJEHiA0AURSHFA8DZs2eZm5sLA7m+T79SqbC4uEij0QibwfhZQisrKz1bPcL6Rjg+ztB/Zb6TgaD/cxUARGRcEh0AAGq1tRQf1WqVTqfDc889x759+ygUChw8eJBXvepVAExNTRFFUUjy5s/3/f5+MNhf/ft1AP19/Bv9u5PU6ItIEiQ+APhUD7A2/bNer4c7g/iuX51Oh3q9HtI77Nu3LwwGl8tlgJBPyI8LACEJXHxMYBRBABQIRGS8Eh0A/FW7DwLZbJZms8mFCxeAtf1//cCvmVGr1SgUCpTL5Z59gOMNeHxbSB9IvEEbwu/UQrD4GoCN1hmIiIxSolcC1+v15e9+97vP9h8/derUOIqzY3xgWl1d3Qe8Aty0zbdYBtbVyy6hOhnsaupFdSKbSnQAAJ51zu3a5E5mNn+V32/X1ovqZLCrrBfViWwq0V1AIiIyPAoAIiIplfQAcHLcBRiyq/1+u7leVCeDXc33U53IpkypjkUkLY4dO+bm53d/0lAze2Ir4yNJvwMQEZEhUQAQEUmpxAYAM7vTzJ41szNm9tFxl2crzOywmZ0ys6fN7LSZ/X73+CfM7EUze7L7c3fsNf+2+x2fNbPfih1f9/1VJ7ujTkD1Msiw60QGiKc/SMoPEAH/D3gNkAf+Djg67nJtodyHgLd0f58GngOOAp9gbb/S/vOPdr9bAXh19ztHG3z/N6hOdkedqF7GUidHnXPceuutLg2AebeFOk/qQrC3Amecc2cBzOyrwL3A02Mt1RU4514CXur+vmRmzwA3bPKSe4GvOufqwE/M7Axr3x3Wf/8PDzimOpnAOgHVyyBDrpPEf/9xSGoX0A3AC7HH59j8DyFxzOxm4M3A97uHPmJmT5nZ/WZ2XffYRt9z0PGbNzh3YqhOBlO9rDeEOpmo7z8qSQ0AE83MpoC/BP7AOXcJ+CzwWuDXWbvC+S9jLN5YqE4GU72spzoZnaR2Ab0IHI49vrF7LPHMLMfaH++XnXN/BeCc+0Xs+c8DX+8+3Ox79h9/nrU+zUHnJprqZDDVy3pDrJOJ+P4jt5WBglH/sBaYzrI2sOMHcV4/7nJtodwGfAn4733HD8V+/5es9VsCvJ7eQayzrA1gDfr+b1Sd7I46Ub2MpU5e75wGgft/EnkH4JxrmdlHgEdY+w96v3Pu9JiLtRXvAH4H+KGZPdk99kfAcTP7dcCxdnX2zwGcc6fN7EHWBqdawIedc22AAd//KdXJrqkTUL0MMsw6mYTvP3JKBSEiqaFUEL00CCwiklIKACIiKaUAICKSUgoAIiIppQAgIpJSCgAiIimlACAiklIKACIiKaUAICKSUgoAIpJIV9rVy8z+VXf3sKfM7NtmdtM4yjnJFABEJHHMLAI+A9zF2s5fx83saN9pfwscc869EfgL4D+PtpSTTwFARJIo7AronGsAflevwDl3yjm32n34PdbSPss2KACISBJtd1ev+4BvDHrCzE6Y2byZzZ8/f34Hizj5FABEZKKZ2W8Dx4A/GfS8c+6kc+6Yc+7Y/v37R1u4hEvkfgAiknpb2hXQzH4D+HfAP3Frm8PLNugOQESS6AfAETN7tZnlgfcDD8VPMLM3A58D7nHOvTyGMk48BQARSRznXAvwu3o9AzzY3QHsU2Z2T/e0PwGmgP9tZk+a2UMbvJ1sQF1AIpJIzrmHgYf7jv1x7PffGHmhdhndAYiIpJQCgIhISikAiIiklAKAiEhKKQCIiKSUAoCISEopAIiIpJQCgIhISikAiIiklAKAiEhKKQCIiKSUAoCISEopAIiIpJQCgIhISikAiIiklAKAiEhKKQCIiKSUAoCISEopAIiIpJQCgIhISikAiIiklAKAiEhKKQCIiKSUAoCISEopAIiIpJQCgIhISikAiIiklAKAiEhKKQCIiKSUAoCISEopAIiIpFQZyeUAAAH+SURBVJQCgIhISikAiIiklAKAiEhKKQCIiKSUAoCIJJKZ3Wlmz5rZGTP76IDnC2b2v7rPf9/Mbh59KSebAoCIJI6ZRcBngLuAo8BxMzvad9p9wEXn3K8A/w34T6Mt5eRTABCRJHorcMY5d9Y51wC+Ctzbd869wBe7v/8FcIeZ2QjLOPGy4y6AiMgANwAvxB6fA9620TnOuZaZLQJ7gVfiJ5nZCeBE92HdzH40lBIny69t5SQFABHZ1ZxzJ4GTAGY275w7NuYiDZ2ZzW/lPHUBiUgSvQgcjj2+sXts4DlmlgVmgV+OpHS7hAKAiCTRD4AjZvZqM8sD7wce6jvnIeAD3d/fC/y1c86NsIwTT11AIpI43T79jwCPABFwv3PutJl9Cph3zj0E/Bnw52Z2BrjAWpC4kpNDK3SybOl7mgKmiEg6qQtIRCSlFABERFJKAUBEUuFKqSV2AzO738xe3upaBwUAEdn1tphaYjf4AnDnVk9WABCRNNhKaomJ55z7G9ZmRG2JAoCIpMGg1BI3jKksiaEAICKSUgoAIpIGW0ktkToKACKSBltJLZE6CgAisus551qATy3xDPCgc+70eEu188zsK8DjwK+Z2Tkzu2/T85UKQkQknXQHICKSUgoAIiIppQAgIpJSCgAiIimlACAiklIKACIiKaUAICKSUv8f+byLGdMYI/MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data transformer"
      ],
      "metadata": {
        "id": "K8GPt23nzvQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToTensor(object):\n",
        "    def __call__(self,data):\n",
        "        label, input = data['label'], data['input']\n",
        "\n",
        "        input = input.astype(np.float32)\n",
        "        label = label.astype(np.float32)\n",
        "        \n",
        "        data = {'label': torch.from_numpy(label), 'input': torch.from_numpy(input)}\n",
        "\n",
        "        return data\n",
        "\n",
        "class Normalization(object):\n",
        "    def __init__(self, mean = 0.5, std = 0.5):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, data):\n",
        "        label, input = data['label'], data['input']\n",
        "\n",
        "        input = (input - self.mean) / self.std\n",
        "        data = {'label': label, 'input' : input}\n",
        "\n",
        "        return data\n",
        "\n",
        "class RandomFlip(object):\n",
        "    def __call__(self, data):\n",
        "        label, input = data['label'], data['input']\n",
        "\n",
        "        if np.random.rand() > 0.5:\n",
        "            label = np.fliplr(label)\n",
        "            input = np.fliplr(input)\n",
        "\n",
        "        if np.random.rand() > 0.5:\n",
        "            label = np.flipud(label)\n",
        "            input = np.flipud(input)\n",
        "\n",
        "        data = {'label':label, 'input':input}\n",
        "\n",
        "        return data\n",
        "\n",
        "class Rescale(object):\n",
        "    def __call__(self, data):\n",
        "        label, input = data['label'], data['input']\n",
        "\n",
        "        # h, w = label.shape[1], label.shape[2]\n",
        "        \n",
        "        # small_val = h if h <= w else w\n",
        "        \n",
        "        # exp = 0\n",
        "\n",
        "        # while small_val>=1:\n",
        "        #     small_val = small_val / 2\n",
        "        #     exp += 1\n",
        "        \n",
        "        # resize = 2**(exp-1)\n",
        "\n",
        "        input = cv2.resize(input.transpose(1,2,0), (1024,1024)) \n",
        "        label = cv2.resize(label.transpose(1,2,0), (1024,1024))\n",
        "  \n",
        "        data = {'label':label.transpose(2,0,1), 'input':input}\n",
        "\n",
        "        return data\n",
        "\n",
        "class Rescale_testset(object):\n",
        "    def __call__(self, data):\n",
        "        label, input = data['label'], data['input']\n",
        "\n",
        "        # h, w = label.shape[1], label.shape[2]\n",
        "        \n",
        "        # small_val = h if h <= w else w\n",
        "        \n",
        "        # exp = 0\n",
        "\n",
        "        # while small_val>=1:\n",
        "        #     small_val = small_val / 2\n",
        "        #     exp += 1\n",
        "        \n",
        "        # resize = 2**(exp-1)\n",
        "\n",
        "        input = cv2.resize(input.transpose(1,2,0), (1024,1024)) \n",
        "        label = cv2.resize(label.transpose(1,2,0), (1024,1024))\n",
        "  \n",
        "        data = {'label':label, 'input':input}\n",
        "\n",
        "        return data        "
      ],
      "metadata": {
        "id": "O4p68T-tzyD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data transform example"
      ],
      "metadata": {
        "id": "QIeh69nzQKtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compose transform\n",
        "transform_example_trainset = transforms.Compose([\n",
        "    # transforms.Grayscale(num_output_channels=1),\n",
        "    # transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # transforms.RandomRotation((-72,72)),\n",
        "    # transforms.RandomAffine(0,translate=(0.1,0.1)),\n",
        "    Normalization(mean=0.5, std=0.5),\n",
        "    RandomFlip(),\n",
        "    # Rescale(),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "transform_exmaple_testset = transforms.Compose([\n",
        "    # transforms.Grayscale(num_output_channels=1),\n",
        "    # transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # transforms.RandomRotation((-72,72)),\n",
        "    # transforms.RandomAffine(0,translate=(0.1,0.1)),\n",
        "    Normalization(),\n",
        "    # RandomFlip(),\n",
        "    ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "IBtPeOt47T13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EXA3LJAQz8IH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_db = Dataset(data_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/train', transform=transform_example_trainset)\n",
        "data = dataset_db.__getitem__(1)\n",
        "\n",
        "input = data['input']\n",
        "label = data['label']\n",
        "\n",
        "print(\"=========input==========\")\n",
        "print(input.shape)\n",
        "print(type(input))\n",
        "print(input)\n",
        "print(\"=========label==========\")\n",
        "print(label.shape)\n",
        "print(type(label))\n",
        "print(label)\n",
        "print(\"===================\")\n",
        "plt.subplot(121)\n",
        "plt.imshow(input.squeeze(), cmap='gray')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(label[2], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7S5IIZk7WjS",
        "outputId": "ffac2700-9350-4c2e-eb7d-ef79a3571de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========input==========\n",
            "torch.Size([2048, 2048])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[23.1549, 23.0506, 22.4809,  ..., 28.1161, 28.6763, 29.1965],\n",
            "        [23.3534, 23.0108, 22.4393,  ..., 28.3407, 28.5373, 29.3542],\n",
            "        [24.0697, 23.0865, 22.4852,  ..., 28.4495, 28.5158, 29.1485],\n",
            "        ...,\n",
            "        [32.5115, 31.9423, 31.3404,  ..., 29.5181, 29.3880, 29.4674],\n",
            "        [31.5061, 30.9562, 30.3015,  ..., 30.1901, 30.0526, 29.9397],\n",
            "        [29.9773, 29.9616, 29.4195,  ..., 30.3305, 30.5096, 30.3370]])\n",
            "=========label==========\n",
            "torch.Size([6, 2048, 2048])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
            "===================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efea8c37cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 182
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer"
      ],
      "metadata": {
        "id": "5f57qvSqINlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "batch_size = 2\n",
        "num_epoch = 30\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "q5d6QOUr347b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "class trainer:\n",
        "\n",
        "    def __init__(self, model, train_loader, opt, epoch_size = num_epoch, learning_rate = lr, use_cuda =True):\n",
        "        \n",
        "        self.use_cuda = use_cuda\n",
        "\n",
        "        #Use GPU, model to GPU\n",
        "        if self.use_cuda:\n",
        "            self.net = model.cuda()\n",
        "\n",
        "        else:\n",
        "            self.net = model\n",
        "    \n",
        "        self.train_loader = train_loader\n",
        "        self.optimizer = opt\n",
        "        self.epoch_size = epoch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "        # self.criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "        self.history = {'train_acc':[],'val_acc':[],'test_acc':[],'train_loss':[],'val_loss':[],'test_loss':[]}\n",
        "\n",
        "    def train(self, validation_loader = None):\n",
        "\n",
        "        #Choose optimizer\n",
        "        if self.optimizer == \"SGD\":\n",
        "          optimizer = torch.optim.SGD(self.net.parameters(), lr = self.learning_rate)\n",
        "        elif self.optimizer == \"Adam\":\n",
        "          optimizer = torch.optim.Adam(self.net.parameters(), lr = self.learning_rate)\n",
        "        elif self.optimizer == \"Adagrad\":\n",
        "          optimizer = torch.optim.Adagrad(self.net.parameters(), lr = self.learning_rate)\n",
        "        elif self.optimizer == \"RMSprop\":\n",
        "          optimizer = torch.optim.RMSprop(self.net.parameters(), lr = self.learning_rate)\n",
        "\n",
        "        for epoch in tqdm(range(self.epoch_size)):\n",
        "            \n",
        "            self.net.train()\n",
        "            loss_arr = []\n",
        "\n",
        "            for batch, data in enumerate(self.train_loader):\n",
        "                \n",
        "                #forward pass\n",
        "                if self.use_cuda:\n",
        "                    input = data['input'].to(device)\n",
        "                    label = data['label'].to(device)\n",
        "\n",
        "                #unsqueeze depends on batch size to match shape\n",
        "                if batch_size ==1:\n",
        "                    output = self.net(input)\n",
        "                else:\n",
        "                    output = self.net(input.unsqueeze(1))\n",
        "\n",
        "                preds = output.clone()\n",
        "                \n",
        "                for i in range(output.shape[0]):\n",
        "                    for j in range(output.shape[1]):\n",
        "                        preds[i][j] = (output[i][j]-torch.mean(output[i][j]))/torch.std(output[i][j])\n",
        "                        preds[i][j] = torch.sigmoid(output[i][j])\n",
        "\n",
        "                output = preds.clone()\n",
        "                #backward pass & loss\n",
        "                optimizer.zero_grad() #gradient initialization\n",
        "\n",
        "                loss = self.criterion(output, label) #output:prediction, label: answer tensor\n",
        "                loss.backward() #backpropagation\n",
        "                optimizer.step()\n",
        "                \n",
        "                #history\n",
        "                loss_arr += [loss.item()]\n",
        "                \n",
        "                print(\"Train: epoch %04d / %04d | batch %04d / %04d | loss %.4f\" % (epoch+1, self.epoch_size, batch, num_batch_train, np.mean(loss_arr)))\n",
        "                \n",
        "                #tensor board\n",
        "            #     print(label.shape)\n",
        "            #     label = fn_tonumpy(label)\n",
        "            #     input = fn_tonumpy(fn_denorm(input, mean=0.5, std=0.5))\n",
        "            #     output = fn_tonumpy(fn_class(output))\n",
        "\n",
        "            #     writer_train.add_image('label', label, num_batch_train * (epoch-1)+batch, dataformats ='NHWC')\n",
        "            #     writer_train.add_image('input', input, num_batch_train * (epoch-1)+batch, dataformats ='NHWC')\n",
        "            #     writer_train.add_image('output', output, num_batch_train * (epoch-1)+batch, dataformats ='NHWC')\n",
        "            \n",
        "\n",
        "            # writer_train.add_scalar('loss', np.mean(loss_arr), epoch)\n",
        "            self.history['train_loss'].append(np.mean(loss_arr))\n",
        "\n",
        "            if validation_loader != None:\n",
        "                self.validate(validation_loader)\n",
        "\n",
        "            save(ckpt_dir = ckpt_dir, net = self.net, optim = optimizer, epoch = epoch)\n",
        "                ############################\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, data_loader):\n",
        "        \n",
        "        self.net.eval() #no weight update\n",
        "        val_loss_arr = []\n",
        "        \n",
        "        num_correct = 0\n",
        "        num_pixels = 0\n",
        "        \n",
        "\n",
        "        for batch, data in enumerate(data_loader):\n",
        "            #forward pass\n",
        "            if self.use_cuda:\n",
        "                input = data['input'].to(device)\n",
        "                label = data['label'].to(device)\n",
        "            \n",
        "            #unsqueeze depends on batch size to match shape\n",
        "            if batch_size ==1:\n",
        "                output = self.net(input)\n",
        "            else:\n",
        "                output = self.net(input.unsqueeze(1))\n",
        "            \n",
        "            #loss function\n",
        "            val_loss = self.criterion(output, label)\n",
        "            val_loss_arr += [val_loss.item()]\n",
        "\n",
        "            print(\"Val loss %.4f\" % (np.mean(val_loss_arr)))\n",
        "            \n",
        "            #dice loss\n",
        "            for j in range(output.shape[0]):\n",
        "                output = torch.clone(output[j]) #(N, 6, 1024,1024)\n",
        "\n",
        "                for i in range(output.shape[0]):\n",
        "                    output[i] = (output[i]-torch.mean(output[i]))/torch.std(output[i])\n",
        "                    output[i] = torch.sigmoid(output[i])\n",
        "                    output[i] = fn_classifier(output[i])\n",
        "            \n",
        "            num_correct += (output == label).sum()\n",
        "            num_pixels += torch.numel(output)\n",
        "            \n",
        "            dice_score = (2*(num_correct).sum()) / ((output+label).sum() + 1e-8)\n",
        "\n",
        "            print(f\"Dice score : {dice_score}\")\n",
        "\n",
        "        #     #tensor board\n",
        "        #     label = fn_tonumpy(label)\n",
        "        #     input = fn_tonumpy(fn_denorm(input, mean=0.5, std=0.5))\n",
        "        #     output = fn_tonumpy(fn_class(output))\n",
        "\n",
        "        #     writer_val.add_image('label', label, num_batch_train * (epoch-1)+batch, dataformats ='NHWC')\n",
        "        #     writer_val.add_image('input', input, num_batch_train * (epoch-1)+batch, dataformats ='NHWC')\n",
        "        #     writer_val.add_image('output', output, num_batch_train * (epoch-1)+batch, dataformats ='NHWC')\n",
        "\n",
        "        # writer_val.add_scalar('loss', np.mean(val_loss_arr), epoch)\n",
        "\n",
        "        if  data_loader != self.train_loader: \n",
        "            self.history['val_loss'].append(np.mean(val_loss_arr))\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test(self, data_loader):\n",
        "        \n",
        "        test_img_arr = os.listdir(os.path.join(test_dir,'img'))\n",
        "        test_img_arr.sort()\n",
        "            \n",
        "        self.net.eval() #no weight update\n",
        "        test_loss_arr = []\n",
        "\n",
        "        for batch, data in enumerate(data_loader):\n",
        "            #forward pass\n",
        "            if self.use_cuda:\n",
        "                input = data['input'].to(device)\n",
        "                # label = data['label'].to(device)\n",
        "\n",
        "            #unsqueeze depends on batch size to match shape\n",
        "            if batch_size ==1:\n",
        "                output = self.net(input)\n",
        "            else:\n",
        "                output = self.net(input.unsqueeze(1))\n",
        "            \n",
        "            #######################################\n",
        "            ###there is no backward pass in test###\n",
        "            #######################################\n",
        "\n",
        "            #loss function\n",
        "            # test_loss = self.criterion(output, label)\n",
        "\n",
        "            # test_loss_arr += [test_loss.item()]\n",
        "\n",
        "            #print test loss\n",
        "            # print(\"Test:  batch %04d / %04d | loss %.4f\" % (batch, num_batch_test, np.mean(test_loss_arr)))\n",
        "\n",
        "            #tensor board\n",
        "            # label = fn_tonumpy(label)\n",
        "\n",
        "\n",
        "            #save output image and numpy \n",
        "            \n",
        "            input = fn_denorm(input, mean=0.5, std=0.5)\n",
        "            input = fn_tonumpy(input)\n",
        "\n",
        "            # print(type(input)) #<class 'torch.Tensor'>\n",
        "            # print(type(output)) #<class 'torch.Tensor'>\n",
        "\n",
        "            # output = fn_tonumpy(fn_classifier(output))\n",
        "            # output = fn_tonumpy(output)\n",
        "\n",
        "            # print(f\"input: {type(input)} : {input.shape}\") #(4, 1024, 1024)\n",
        "            # print(f\"output: {type(output)} : {output.shape}\") #(4, 6, 1024, 1024)\n",
        "            print(1)\n",
        "            for j in range(output.shape[0]):\n",
        "                \n",
        "                id = num_batch_test * (batch -1)+j\n",
        "                print(2)\n",
        "                # plt.imsave(os.path.join(result_dir, 'png' ,'label_%04d.png' %id), label[j].squeeze(), cmap='gray')\n",
        "                plt.imsave(os.path.join(result_dir, 'png' ,'input_%04d.png' %id), input[j].squeeze(), cmap='gray')\n",
        "\n",
        "\n",
        "                print(3)\n",
        "                preds = output[j].clone()  # (6,1024,1024)\n",
        "                for i in range(preds.shape[0]):\n",
        "                    preds[i] = (preds[i]-torch.mean(preds[i]))/torch.std(preds[i])\n",
        "                    preds[i] = torch.sigmoid(preds[i])\n",
        "                    preds[i] = fn_classifier(preds[i])\n",
        "                \n",
        "                preds = fn_tonumpy(preds)\n",
        "                np.save(os.path.join(result_dir, 'numpy','output_%04d.npy' %id), preds.squeeze())\n",
        "                print(4)\n",
        "\n",
        "                # output_ = fn_tonumpy(fn_classifier(output))\n",
        "                preds_torch = torch.Tensor(preds)\n",
        "                print(5)\n",
        "                for k in range(6):\n",
        "                    plt.imsave(os.path.join(result_dir, 'png' ,'output_%04d_%04d.png' %(id, k)), preds[k].squeeze(), cmap='gray')\n",
        "\n",
        "                # print(f\"input shape {input[j].squeeze().shape}\") #(1024, 1024)\n",
        "                # print(f\"output shape {output[j].squeeze().shape}\") #(6, 1024, 1024)\n",
        "                \n",
        "                # np.save(os.path.join(result_dir, 'numpy','label_%04d.npy' %id), label[j].squeeze())\n",
        "                \n",
        "                # np.save(os.path.join(result_dir, 'numpy','input_%04d.npy' %id), input[j].squeeze())\n",
        "                # np.save(os.path.join(result_dir, 'numpy','output_%04d.npy' %id), output[j].squeeze())\n",
        "                \n",
        "\n",
        "\n",
        "\n",
        "                if test_img_arr:\n",
        "                    print(test_img_arr)\n",
        "                    test_input_abs_path = os.path.join(test_dir, 'img', test_img_arr[0])\n",
        "                    images = sitk.ReadImage(test_input_abs_path)\n",
        "                    test_input_shape =sitk.GetArrayFromImage(images).shape #(1,3232,2588)\n",
        "\n",
        "                    print(test_input_shape)\n",
        "                    print(output.shape) #(2,6,1024,1024)\n",
        "                    print(output[j].shape) #(6,1024,1024)\n",
        "                    # 7 채널로..\n",
        "                    preds_tensor = torch.cat((preds_torch, preds_torch[5].unsqueeze(0)))\n",
        "                    preds_np = cv2.resize(fn_tonumpy(preds_tensor).transpose(1,2,0), (test_input_shape[2],test_input_shape[1])) \n",
        "                    \n",
        "                    print(np.amax(preds_np))\n",
        "                    #7채널\n",
        "                    # output_np = cv2.resize(fn_tonumpy(output[j]).transpose(1,2,0), (test_input_shape[2],test_input_shape[1])) \n",
        "                    \n",
        "                    print(preds_np.shape)\n",
        "\n",
        "                    \n",
        "                    #preds save\n",
        "                    np.save(os.path.join(board_dir, test_img_arr.pop(0)[:-4]), np.uint8(preds_np))\n",
        "\n",
        "                    #output save\n",
        "                    # np.save(os.path.join(board_dir, test_img_arr.pop(0)[:-4]), np.uint8(output_np))\n",
        "                \n",
        "                \n",
        "        self.history['test_loss'].append(np.mean(test_loss_arr))\n",
        "\n",
        "        # print(\"Average test: loss %.4f\" % (np.mean(test_loss_arr)))\n",
        "\n"
      ],
      "metadata": {
        "id": "XRrrIgui2sdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data transform"
      ],
      "metadata": {
        "id": "sNkoc8ofPfO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compose transform\n",
        "transform_wholeset = transforms.Compose([\n",
        "    # transforms.Grayscale(num_output_channels=1),\n",
        "    # transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # transforms.RandomRotation((-72,72)),\n",
        "    # transforms.RandomAffine(0,translate=(0.1,0.1)),\n",
        "    Normalization(),\n",
        "    RandomFlip(),\n",
        "    Rescale(),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "transform_testset = transforms.Compose([\n",
        "    # transforms.Grayscale(num_output_channels=1),\n",
        "    # transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # transforms.RandomRotation((-72,72)),\n",
        "    # transforms.RandomAffine(0,translate=(0.1,0.1)),\n",
        "    Normalization(),\n",
        "    # RandomFlip(),\n",
        "    Rescale_testset(),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "#train, val dataset, dataloader\n",
        "whole_dataset = Dataset(data_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/train', transform = transform_wholeset)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(whole_dataset, [100, 20])\n",
        "test_dataset = Dataset(data_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/test' , transform = transform_testset)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
        "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers = 8)"
      ],
      "metadata": {
        "id": "ZH_ElWavs423"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(test_dataset))\n",
        "# print(test_dataset.lst_input[0])\n",
        "# print(test_dataset.lst_label)\n",
        "# # aaa = test_dataset.__getitem__(1)\n",
        "# # aaa['input']\n",
        "# print(len(test_loader.dataset))\n",
        "\n",
        "\n",
        "# for batch, data in enumerate(test_loader):\n",
        "#     print(data['input'].shape)\n",
        "\n",
        "#     print(data['input'])\n",
        "    \n",
        "#     print(data['input'].unsqueeze(1).shape)\n",
        "    \n",
        "#     print(data['input'].unsqueeze(1))\n",
        "\n",
        "#     break\n",
        "#     # #forward pass\n",
        "    # if self.use_cuda:\n",
        "    #     input = data['input'].to(device)\n",
        "    #     label = data['label'].to(device)\n",
        "\n",
        "    # output = self.net(input.unsqueeze(1))"
      ],
      "metadata": {
        "id": "UWDD_QKTvmmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Before Train"
      ],
      "metadata": {
        "id": "tB4Ir8fqqwnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#other variables\n",
        "num_data_train = len(train_dataset)\n",
        "num_data_val = len(val_dataset)\n",
        "num_data_test = len(test_dataset)\n",
        "\n",
        "num_batch_train = np.ceil(num_data_train / batch_size)\n",
        "num_batch_val = np.ceil(num_data_val / batch_size)\n",
        "num_batch_test = np.ceil(num_data_test / batch_size)\n",
        "\n",
        "\n",
        "# 기타 function 설정\n",
        "# fn_tonumpy = lambda x : x.to('cpu').detach().numpy().transpose(0,2,3,1) # device 위에 올라간 텐서를 detach 한 뒤 numpy로 변환\n",
        "fn_tonumpy = lambda x : x.to('cpu').detach().numpy() # device 위에 올라간 텐서를 detach 한 뒤 numpy로 변환\n",
        "fn_denorm = lambda x, mean, std : (x * std) + mean \n",
        "fn_classifier = lambda x :  1.0 * (x > 0.65)  # threshold 0.5 기준으로 indicator function으로 classifier 구현\n",
        "\n",
        "# tensorboard, SummaryWriter\n",
        "writer_train = SummaryWriter(log_dir = os.path.join(log_dir, 'train'))\n",
        "writer_val = SummaryWriter(log_dir = os.path.join(log_dir, 'val'))\n",
        "\n",
        "#save network\n",
        "def save(ckpt_dir, net, optim, epoch):\n",
        "    if not os.path.exists(ckpt_dir):\n",
        "        os.makedirs(ckpt_dir)\n",
        "\n",
        "    torch.save({'net':net.state_dict(),'optim':optim.state_dict()},'%s/model_epoch%d.pth'%(ckpt_dir,epoch))\n",
        "\n",
        "#load network\n",
        "def load(ckpt_dir, net, optim):\n",
        "    if not os.path.exists(ckpt_dir):\n",
        "        epoch = 0\n",
        "        return net, optim, epoch\n",
        "\n",
        "    ckpt_lst = os.listdir(ckpt_dir)\n",
        "    ckpt_lst.sort(key=lambda f: int(''.join(filter(str.isdigit,f))))\n",
        "\n",
        "    dict_model = torch.load('%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
        "\n",
        "    net.load_state_dict(dict_model['net'])\n",
        "    optim.load_state_dict(dict_model['optim'])\n",
        "    epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n",
        "\n",
        "    return net, optim, epoch\n"
      ],
      "metadata": {
        "id": "S4CL1gldqwHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## example model summary"
      ],
      "metadata": {
        "id": "Cp72Zn3C2p_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_model = UNET()\n",
        "example_model.cuda()\n",
        "\n",
        "summary(example_model, input_size=(1,1024,1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cNQu3ef6w-J",
        "outputId": "8d223f0d-841d-43cf-fcb6-dacee56265b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1       [-1, 64, 1024, 1024]             576\n",
            "       BatchNorm2d-2       [-1, 64, 1024, 1024]             128\n",
            "              ReLU-3       [-1, 64, 1024, 1024]               0\n",
            "            Conv2d-4       [-1, 64, 1024, 1024]          36,864\n",
            "       BatchNorm2d-5       [-1, 64, 1024, 1024]             128\n",
            "              ReLU-6       [-1, 64, 1024, 1024]               0\n",
            "        DoubleConv-7       [-1, 64, 1024, 1024]               0\n",
            "         MaxPool2d-8         [-1, 64, 512, 512]               0\n",
            "            Conv2d-9        [-1, 128, 512, 512]          73,728\n",
            "      BatchNorm2d-10        [-1, 128, 512, 512]             256\n",
            "             ReLU-11        [-1, 128, 512, 512]               0\n",
            "           Conv2d-12        [-1, 128, 512, 512]         147,456\n",
            "      BatchNorm2d-13        [-1, 128, 512, 512]             256\n",
            "             ReLU-14        [-1, 128, 512, 512]               0\n",
            "       DoubleConv-15        [-1, 128, 512, 512]               0\n",
            "        MaxPool2d-16        [-1, 128, 256, 256]               0\n",
            "           Conv2d-17        [-1, 256, 256, 256]         294,912\n",
            "      BatchNorm2d-18        [-1, 256, 256, 256]             512\n",
            "             ReLU-19        [-1, 256, 256, 256]               0\n",
            "           Conv2d-20        [-1, 256, 256, 256]         589,824\n",
            "      BatchNorm2d-21        [-1, 256, 256, 256]             512\n",
            "             ReLU-22        [-1, 256, 256, 256]               0\n",
            "       DoubleConv-23        [-1, 256, 256, 256]               0\n",
            "        MaxPool2d-24        [-1, 256, 128, 128]               0\n",
            "           Conv2d-25        [-1, 512, 128, 128]       1,179,648\n",
            "      BatchNorm2d-26        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-27        [-1, 512, 128, 128]               0\n",
            "           Conv2d-28        [-1, 512, 128, 128]       2,359,296\n",
            "      BatchNorm2d-29        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-30        [-1, 512, 128, 128]               0\n",
            "       DoubleConv-31        [-1, 512, 128, 128]               0\n",
            "        MaxPool2d-32          [-1, 512, 64, 64]               0\n",
            "           Conv2d-33         [-1, 1024, 64, 64]       4,718,592\n",
            "      BatchNorm2d-34         [-1, 1024, 64, 64]           2,048\n",
            "             ReLU-35         [-1, 1024, 64, 64]               0\n",
            "           Conv2d-36         [-1, 1024, 64, 64]       9,437,184\n",
            "      BatchNorm2d-37         [-1, 1024, 64, 64]           2,048\n",
            "             ReLU-38         [-1, 1024, 64, 64]               0\n",
            "       DoubleConv-39         [-1, 1024, 64, 64]               0\n",
            "  ConvTranspose2d-40        [-1, 512, 128, 128]       2,097,664\n",
            "           Conv2d-41        [-1, 512, 128, 128]       4,718,592\n",
            "      BatchNorm2d-42        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-43        [-1, 512, 128, 128]               0\n",
            "           Conv2d-44        [-1, 512, 128, 128]       2,359,296\n",
            "      BatchNorm2d-45        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-46        [-1, 512, 128, 128]               0\n",
            "       DoubleConv-47        [-1, 512, 128, 128]               0\n",
            "  ConvTranspose2d-48        [-1, 256, 256, 256]         524,544\n",
            "           Conv2d-49        [-1, 256, 256, 256]       1,179,648\n",
            "      BatchNorm2d-50        [-1, 256, 256, 256]             512\n",
            "             ReLU-51        [-1, 256, 256, 256]               0\n",
            "           Conv2d-52        [-1, 256, 256, 256]         589,824\n",
            "      BatchNorm2d-53        [-1, 256, 256, 256]             512\n",
            "             ReLU-54        [-1, 256, 256, 256]               0\n",
            "       DoubleConv-55        [-1, 256, 256, 256]               0\n",
            "  ConvTranspose2d-56        [-1, 128, 512, 512]         131,200\n",
            "           Conv2d-57        [-1, 128, 512, 512]         294,912\n",
            "      BatchNorm2d-58        [-1, 128, 512, 512]             256\n",
            "             ReLU-59        [-1, 128, 512, 512]               0\n",
            "           Conv2d-60        [-1, 128, 512, 512]         147,456\n",
            "      BatchNorm2d-61        [-1, 128, 512, 512]             256\n",
            "             ReLU-62        [-1, 128, 512, 512]               0\n",
            "       DoubleConv-63        [-1, 128, 512, 512]               0\n",
            "  ConvTranspose2d-64       [-1, 64, 1024, 1024]          32,832\n",
            "           Conv2d-65       [-1, 64, 1024, 1024]          73,728\n",
            "      BatchNorm2d-66       [-1, 64, 1024, 1024]             128\n",
            "             ReLU-67       [-1, 64, 1024, 1024]               0\n",
            "           Conv2d-68       [-1, 64, 1024, 1024]          36,864\n",
            "      BatchNorm2d-69       [-1, 64, 1024, 1024]             128\n",
            "             ReLU-70       [-1, 64, 1024, 1024]               0\n",
            "       DoubleConv-71       [-1, 64, 1024, 1024]               0\n",
            "           Conv2d-72        [-1, 7, 1024, 1024]             455\n",
            "================================================================\n",
            "Total params: 31,036,871\n",
            "Trainable params: 31,036,871\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 4.00\n",
            "Forward/backward pass size (MB): 14920.00\n",
            "Params size (MB): 118.40\n",
            "Estimated Total Size (MB): 15042.40\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_model_64 = UNet()\n",
        "example_model_64.cuda()\n",
        "\n",
        "summary(example_model_64, input_size=(1,1024,1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0I0bzMc2s5w",
        "outputId": "1990212d-1b33-4b0f-f2b6-1f42582554c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1       [-1, 64, 1024, 1024]             640\n",
            "       BatchNorm2d-2       [-1, 64, 1024, 1024]             128\n",
            "              ReLU-3       [-1, 64, 1024, 1024]               0\n",
            "            Conv2d-4       [-1, 64, 1024, 1024]          36,928\n",
            "       BatchNorm2d-5       [-1, 64, 1024, 1024]             128\n",
            "              ReLU-6       [-1, 64, 1024, 1024]               0\n",
            "         MaxPool2d-7         [-1, 64, 512, 512]               0\n",
            "            Conv2d-8        [-1, 128, 512, 512]          73,856\n",
            "       BatchNorm2d-9        [-1, 128, 512, 512]             256\n",
            "             ReLU-10        [-1, 128, 512, 512]               0\n",
            "           Conv2d-11        [-1, 128, 512, 512]         147,584\n",
            "      BatchNorm2d-12        [-1, 128, 512, 512]             256\n",
            "             ReLU-13        [-1, 128, 512, 512]               0\n",
            "        MaxPool2d-14        [-1, 128, 256, 256]               0\n",
            "           Conv2d-15        [-1, 256, 256, 256]         295,168\n",
            "      BatchNorm2d-16        [-1, 256, 256, 256]             512\n",
            "             ReLU-17        [-1, 256, 256, 256]               0\n",
            "           Conv2d-18        [-1, 256, 256, 256]         590,080\n",
            "      BatchNorm2d-19        [-1, 256, 256, 256]             512\n",
            "             ReLU-20        [-1, 256, 256, 256]               0\n",
            "        MaxPool2d-21        [-1, 256, 128, 128]               0\n",
            "           Conv2d-22        [-1, 512, 128, 128]       1,180,160\n",
            "      BatchNorm2d-23        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-24        [-1, 512, 128, 128]               0\n",
            "           Conv2d-25        [-1, 512, 128, 128]       2,359,808\n",
            "      BatchNorm2d-26        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-27        [-1, 512, 128, 128]               0\n",
            "        MaxPool2d-28          [-1, 512, 64, 64]               0\n",
            "           Conv2d-29         [-1, 1024, 64, 64]       4,719,616\n",
            "      BatchNorm2d-30         [-1, 1024, 64, 64]           2,048\n",
            "             ReLU-31         [-1, 1024, 64, 64]               0\n",
            "           Conv2d-32          [-1, 512, 64, 64]       4,719,104\n",
            "      BatchNorm2d-33          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-34          [-1, 512, 64, 64]               0\n",
            "  ConvTranspose2d-35        [-1, 512, 128, 128]       1,049,088\n",
            "           Conv2d-36        [-1, 512, 128, 128]       4,719,104\n",
            "      BatchNorm2d-37        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-38        [-1, 512, 128, 128]               0\n",
            "           Conv2d-39        [-1, 256, 128, 128]       1,179,904\n",
            "      BatchNorm2d-40        [-1, 256, 128, 128]             512\n",
            "             ReLU-41        [-1, 256, 128, 128]               0\n",
            "  ConvTranspose2d-42        [-1, 256, 256, 256]         262,400\n",
            "           Conv2d-43        [-1, 256, 256, 256]       1,179,904\n",
            "      BatchNorm2d-44        [-1, 256, 256, 256]             512\n",
            "             ReLU-45        [-1, 256, 256, 256]               0\n",
            "           Conv2d-46        [-1, 128, 256, 256]         295,040\n",
            "      BatchNorm2d-47        [-1, 128, 256, 256]             256\n",
            "             ReLU-48        [-1, 128, 256, 256]               0\n",
            "  ConvTranspose2d-49        [-1, 128, 512, 512]          65,664\n",
            "           Conv2d-50        [-1, 128, 512, 512]         295,040\n",
            "      BatchNorm2d-51        [-1, 128, 512, 512]             256\n",
            "             ReLU-52        [-1, 128, 512, 512]               0\n",
            "           Conv2d-53         [-1, 64, 512, 512]          73,792\n",
            "      BatchNorm2d-54         [-1, 64, 512, 512]             128\n",
            "             ReLU-55         [-1, 64, 512, 512]               0\n",
            "  ConvTranspose2d-56       [-1, 64, 1024, 1024]          16,448\n",
            "           Conv2d-57       [-1, 64, 1024, 1024]          73,792\n",
            "      BatchNorm2d-58       [-1, 64, 1024, 1024]             128\n",
            "             ReLU-59       [-1, 64, 1024, 1024]               0\n",
            "           Conv2d-60       [-1, 64, 1024, 1024]          36,928\n",
            "      BatchNorm2d-61       [-1, 64, 1024, 1024]             128\n",
            "             ReLU-62       [-1, 64, 1024, 1024]               0\n",
            "           Conv2d-63        [-1, 6, 1024, 1024]             390\n",
            "================================================================\n",
            "Total params: 23,380,294\n",
            "Trainable params: 23,380,294\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 4.00\n",
            "Forward/backward pass size (MB): 12240.00\n",
            "Params size (MB): 89.19\n",
            "Estimated Total Size (MB): 12333.19\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_model_32 = UNet()\n",
        "example_model_32.cuda()\n",
        "\n",
        "summary(example_model_32, input_size=(1,1024,1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN5EU-i8NrwG",
        "outputId": "4cc8aee7-50cc-4edd-8eab-642edcd3201b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 256, 128, 128]) torch.Size([2, 256, 128, 128])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1       [-1, 32, 1024, 1024]             320\n",
            "       BatchNorm2d-2       [-1, 32, 1024, 1024]              64\n",
            "              ReLU-3       [-1, 32, 1024, 1024]               0\n",
            "            Conv2d-4       [-1, 32, 1024, 1024]           9,248\n",
            "       BatchNorm2d-5       [-1, 32, 1024, 1024]              64\n",
            "              ReLU-6       [-1, 32, 1024, 1024]               0\n",
            "         MaxPool2d-7         [-1, 32, 512, 512]               0\n",
            "            Conv2d-8         [-1, 64, 512, 512]          18,496\n",
            "       BatchNorm2d-9         [-1, 64, 512, 512]             128\n",
            "             ReLU-10         [-1, 64, 512, 512]               0\n",
            "           Conv2d-11         [-1, 64, 512, 512]          36,928\n",
            "      BatchNorm2d-12         [-1, 64, 512, 512]             128\n",
            "             ReLU-13         [-1, 64, 512, 512]               0\n",
            "        MaxPool2d-14         [-1, 64, 256, 256]               0\n",
            "           Conv2d-15        [-1, 128, 256, 256]          73,856\n",
            "      BatchNorm2d-16        [-1, 128, 256, 256]             256\n",
            "             ReLU-17        [-1, 128, 256, 256]               0\n",
            "           Conv2d-18        [-1, 128, 256, 256]         147,584\n",
            "      BatchNorm2d-19        [-1, 128, 256, 256]             256\n",
            "             ReLU-20        [-1, 128, 256, 256]               0\n",
            "        MaxPool2d-21        [-1, 128, 128, 128]               0\n",
            "           Conv2d-22        [-1, 256, 128, 128]         295,168\n",
            "      BatchNorm2d-23        [-1, 256, 128, 128]             512\n",
            "             ReLU-24        [-1, 256, 128, 128]               0\n",
            "           Conv2d-25        [-1, 256, 128, 128]         590,080\n",
            "      BatchNorm2d-26        [-1, 256, 128, 128]             512\n",
            "             ReLU-27        [-1, 256, 128, 128]               0\n",
            "        MaxPool2d-28          [-1, 256, 64, 64]               0\n",
            "           Conv2d-29          [-1, 512, 64, 64]       1,180,160\n",
            "      BatchNorm2d-30          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-31          [-1, 512, 64, 64]               0\n",
            "           Conv2d-32          [-1, 256, 64, 64]       1,179,904\n",
            "      BatchNorm2d-33          [-1, 256, 64, 64]             512\n",
            "             ReLU-34          [-1, 256, 64, 64]               0\n",
            "  ConvTranspose2d-35        [-1, 256, 128, 128]         262,400\n",
            "           Conv2d-36        [-1, 256, 128, 128]       1,179,904\n",
            "      BatchNorm2d-37        [-1, 256, 128, 128]             512\n",
            "             ReLU-38        [-1, 256, 128, 128]               0\n",
            "           Conv2d-39        [-1, 128, 128, 128]         295,040\n",
            "      BatchNorm2d-40        [-1, 128, 128, 128]             256\n",
            "             ReLU-41        [-1, 128, 128, 128]               0\n",
            "  ConvTranspose2d-42        [-1, 128, 256, 256]          65,664\n",
            "           Conv2d-43        [-1, 128, 256, 256]         295,040\n",
            "      BatchNorm2d-44        [-1, 128, 256, 256]             256\n",
            "             ReLU-45        [-1, 128, 256, 256]               0\n",
            "           Conv2d-46         [-1, 64, 256, 256]          73,792\n",
            "      BatchNorm2d-47         [-1, 64, 256, 256]             128\n",
            "             ReLU-48         [-1, 64, 256, 256]               0\n",
            "  ConvTranspose2d-49         [-1, 64, 512, 512]          16,448\n",
            "           Conv2d-50         [-1, 64, 512, 512]          73,792\n",
            "      BatchNorm2d-51         [-1, 64, 512, 512]             128\n",
            "             ReLU-52         [-1, 64, 512, 512]               0\n",
            "           Conv2d-53         [-1, 32, 512, 512]          18,464\n",
            "      BatchNorm2d-54         [-1, 32, 512, 512]              64\n",
            "             ReLU-55         [-1, 32, 512, 512]               0\n",
            "  ConvTranspose2d-56       [-1, 32, 1024, 1024]           4,128\n",
            "           Conv2d-57       [-1, 32, 1024, 1024]          18,464\n",
            "      BatchNorm2d-58       [-1, 32, 1024, 1024]              64\n",
            "             ReLU-59       [-1, 32, 1024, 1024]               0\n",
            "           Conv2d-60       [-1, 32, 1024, 1024]           9,248\n",
            "      BatchNorm2d-61       [-1, 32, 1024, 1024]              64\n",
            "             ReLU-62       [-1, 32, 1024, 1024]               0\n",
            "           Conv2d-63        [-1, 6, 1024, 1024]             198\n",
            "================================================================\n",
            "Total params: 5,849,254\n",
            "Trainable params: 5,849,254\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 4.00\n",
            "Forward/backward pass size (MB): 6144.00\n",
            "Params size (MB): 22.31\n",
            "Estimated Total Size (MB): 6170.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "2YE49-OEd_Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Tvoa6l6lHwXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Spine_segment = UNET()\n",
        "Spine_segment.cuda()\n",
        "trainer_Spine_segment = trainer(Spine_segment, train_loader,\"Adam\", epoch_size=20, learning_rate=0.001)\n",
        "trainer_Spine_segment.train(val_loader)"
      ],
      "metadata": {
        "id": "ZWfK7q9K0fN-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1e3eb1c-3c17-43de-d9a4-ba19b6c14de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0001 / 0020 | batch 0000 / 0050 | loss 0.9744\n",
            "Train: epoch 0001 / 0020 | batch 0001 / 0050 | loss 0.9702\n",
            "Train: epoch 0001 / 0020 | batch 0002 / 0050 | loss 0.9644\n",
            "Train: epoch 0001 / 0020 | batch 0003 / 0050 | loss 0.9591\n",
            "Train: epoch 0001 / 0020 | batch 0004 / 0050 | loss 0.9536\n",
            "Train: epoch 0001 / 0020 | batch 0005 / 0050 | loss 0.9487\n",
            "Train: epoch 0001 / 0020 | batch 0006 / 0050 | loss 0.9444\n",
            "Train: epoch 0001 / 0020 | batch 0007 / 0050 | loss 0.9405\n",
            "Train: epoch 0001 / 0020 | batch 0008 / 0050 | loss 0.9370\n",
            "Train: epoch 0001 / 0020 | batch 0009 / 0050 | loss 0.9341\n",
            "Train: epoch 0001 / 0020 | batch 0010 / 0050 | loss 0.9312\n",
            "Train: epoch 0001 / 0020 | batch 0011 / 0050 | loss 0.9287\n",
            "Train: epoch 0001 / 0020 | batch 0012 / 0050 | loss 0.9261\n",
            "Train: epoch 0001 / 0020 | batch 0013 / 0050 | loss 0.9237\n",
            "Train: epoch 0001 / 0020 | batch 0014 / 0050 | loss 0.9213\n",
            "Train: epoch 0001 / 0020 | batch 0015 / 0050 | loss 0.9191\n",
            "Train: epoch 0001 / 0020 | batch 0016 / 0050 | loss 0.9169\n",
            "Train: epoch 0001 / 0020 | batch 0017 / 0050 | loss 0.9148\n",
            "Train: epoch 0001 / 0020 | batch 0018 / 0050 | loss 0.9128\n",
            "Train: epoch 0001 / 0020 | batch 0019 / 0050 | loss 0.9107\n",
            "Train: epoch 0001 / 0020 | batch 0020 / 0050 | loss 0.9088\n",
            "Train: epoch 0001 / 0020 | batch 0021 / 0050 | loss 0.9069\n",
            "Train: epoch 0001 / 0020 | batch 0022 / 0050 | loss 0.9050\n",
            "Train: epoch 0001 / 0020 | batch 0023 / 0050 | loss 0.9032\n",
            "Train: epoch 0001 / 0020 | batch 0024 / 0050 | loss 0.9015\n",
            "Train: epoch 0001 / 0020 | batch 0025 / 0050 | loss 0.8998\n",
            "Train: epoch 0001 / 0020 | batch 0026 / 0050 | loss 0.8980\n",
            "Train: epoch 0001 / 0020 | batch 0027 / 0050 | loss 0.8963\n",
            "Train: epoch 0001 / 0020 | batch 0028 / 0050 | loss 0.8946\n",
            "Train: epoch 0001 / 0020 | batch 0029 / 0050 | loss 0.8929\n",
            "Train: epoch 0001 / 0020 | batch 0030 / 0050 | loss 0.8912\n",
            "Train: epoch 0001 / 0020 | batch 0031 / 0050 | loss 0.8896\n",
            "Train: epoch 0001 / 0020 | batch 0032 / 0050 | loss 0.8879\n",
            "Train: epoch 0001 / 0020 | batch 0033 / 0050 | loss 0.8863\n",
            "Train: epoch 0001 / 0020 | batch 0034 / 0050 | loss 0.8847\n",
            "Train: epoch 0001 / 0020 | batch 0035 / 0050 | loss 0.8830\n",
            "Train: epoch 0001 / 0020 | batch 0036 / 0050 | loss 0.8814\n",
            "Train: epoch 0001 / 0020 | batch 0037 / 0050 | loss 0.8798\n",
            "Train: epoch 0001 / 0020 | batch 0038 / 0050 | loss 0.8783\n",
            "Train: epoch 0001 / 0020 | batch 0039 / 0050 | loss 0.8767\n",
            "Train: epoch 0001 / 0020 | batch 0040 / 0050 | loss 0.8753\n",
            "Train: epoch 0001 / 0020 | batch 0041 / 0050 | loss 0.8737\n",
            "Train: epoch 0001 / 0020 | batch 0042 / 0050 | loss 0.8722\n",
            "Train: epoch 0001 / 0020 | batch 0043 / 0050 | loss 0.8708\n",
            "Train: epoch 0001 / 0020 | batch 0044 / 0050 | loss 0.8693\n",
            "Train: epoch 0001 / 0020 | batch 0045 / 0050 | loss 0.8678\n",
            "Train: epoch 0001 / 0020 | batch 0046 / 0050 | loss 0.8663\n",
            "Train: epoch 0001 / 0020 | batch 0047 / 0050 | loss 0.8649\n",
            "Train: epoch 0001 / 0020 | batch 0048 / 0050 | loss 0.8635\n",
            "Train: epoch 0001 / 0020 | batch 0049 / 0050 | loss 0.8621\n",
            "Val loss 0.2347\n",
            "Dice score : 12.20675277709961\n",
            "Val loss 0.2339\n",
            "Dice score : 15.115570068359375\n",
            "Val loss 0.2341\n",
            "Dice score : 24.49225616455078\n",
            "Val loss 0.2326\n",
            "Dice score : 53.811866760253906\n",
            "Val loss 0.2326\n",
            "Dice score : 65.9258804321289\n",
            "Val loss 0.2320\n",
            "Dice score : 53.72291564941406\n",
            "Val loss 0.2353\n",
            "Dice score : 44.56219482421875\n",
            "Val loss 0.2346\n",
            "Dice score : 75.77572631835938\n",
            "Val loss 0.2340\n",
            "Dice score : 87.2259750366211\n",
            "Val loss 0.2349\n",
            "Dice score : 91.79064178466797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [01:16<24:18, 76.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0002 / 0020 | batch 0000 / 0050 | loss 0.7891\n",
            "Train: epoch 0002 / 0020 | batch 0001 / 0050 | loss 0.7900\n",
            "Train: epoch 0002 / 0020 | batch 0002 / 0050 | loss 0.7889\n",
            "Train: epoch 0002 / 0020 | batch 0003 / 0050 | loss 0.7876\n",
            "Train: epoch 0002 / 0020 | batch 0004 / 0050 | loss 0.7863\n",
            "Train: epoch 0002 / 0020 | batch 0005 / 0050 | loss 0.7846\n",
            "Train: epoch 0002 / 0020 | batch 0006 / 0050 | loss 0.7834\n",
            "Train: epoch 0002 / 0020 | batch 0007 / 0050 | loss 0.7821\n",
            "Train: epoch 0002 / 0020 | batch 0008 / 0050 | loss 0.7809\n",
            "Train: epoch 0002 / 0020 | batch 0009 / 0050 | loss 0.7797\n",
            "Train: epoch 0002 / 0020 | batch 0010 / 0050 | loss 0.7788\n",
            "Train: epoch 0002 / 0020 | batch 0011 / 0050 | loss 0.7778\n",
            "Train: epoch 0002 / 0020 | batch 0012 / 0050 | loss 0.7767\n",
            "Train: epoch 0002 / 0020 | batch 0013 / 0050 | loss 0.7758\n",
            "Train: epoch 0002 / 0020 | batch 0014 / 0050 | loss 0.7748\n",
            "Train: epoch 0002 / 0020 | batch 0015 / 0050 | loss 0.7738\n",
            "Train: epoch 0002 / 0020 | batch 0016 / 0050 | loss 0.7730\n",
            "Train: epoch 0002 / 0020 | batch 0017 / 0050 | loss 0.7721\n",
            "Train: epoch 0002 / 0020 | batch 0018 / 0050 | loss 0.7713\n",
            "Train: epoch 0002 / 0020 | batch 0019 / 0050 | loss 0.7704\n",
            "Train: epoch 0002 / 0020 | batch 0020 / 0050 | loss 0.7696\n",
            "Train: epoch 0002 / 0020 | batch 0021 / 0050 | loss 0.7688\n",
            "Train: epoch 0002 / 0020 | batch 0022 / 0050 | loss 0.7680\n",
            "Train: epoch 0002 / 0020 | batch 0023 / 0050 | loss 0.7672\n",
            "Train: epoch 0002 / 0020 | batch 0024 / 0050 | loss 0.7664\n",
            "Train: epoch 0002 / 0020 | batch 0025 / 0050 | loss 0.7656\n",
            "Train: epoch 0002 / 0020 | batch 0026 / 0050 | loss 0.7648\n",
            "Train: epoch 0002 / 0020 | batch 0027 / 0050 | loss 0.7641\n",
            "Train: epoch 0002 / 0020 | batch 0028 / 0050 | loss 0.7633\n",
            "Train: epoch 0002 / 0020 | batch 0029 / 0050 | loss 0.7626\n",
            "Train: epoch 0002 / 0020 | batch 0030 / 0050 | loss 0.7618\n",
            "Train: epoch 0002 / 0020 | batch 0031 / 0050 | loss 0.7611\n",
            "Train: epoch 0002 / 0020 | batch 0032 / 0050 | loss 0.7604\n",
            "Train: epoch 0002 / 0020 | batch 0033 / 0050 | loss 0.7597\n",
            "Train: epoch 0002 / 0020 | batch 0034 / 0050 | loss 0.7590\n",
            "Train: epoch 0002 / 0020 | batch 0035 / 0050 | loss 0.7583\n",
            "Train: epoch 0002 / 0020 | batch 0036 / 0050 | loss 0.7576\n",
            "Train: epoch 0002 / 0020 | batch 0037 / 0050 | loss 0.7570\n",
            "Train: epoch 0002 / 0020 | batch 0038 / 0050 | loss 0.7563\n",
            "Train: epoch 0002 / 0020 | batch 0039 / 0050 | loss 0.7557\n",
            "Train: epoch 0002 / 0020 | batch 0040 / 0050 | loss 0.7551\n",
            "Train: epoch 0002 / 0020 | batch 0041 / 0050 | loss 0.7544\n",
            "Train: epoch 0002 / 0020 | batch 0042 / 0050 | loss 0.7538\n",
            "Train: epoch 0002 / 0020 | batch 0043 / 0050 | loss 0.7532\n",
            "Train: epoch 0002 / 0020 | batch 0044 / 0050 | loss 0.7526\n",
            "Train: epoch 0002 / 0020 | batch 0045 / 0050 | loss 0.7521\n",
            "Train: epoch 0002 / 0020 | batch 0046 / 0050 | loss 0.7515\n",
            "Train: epoch 0002 / 0020 | batch 0047 / 0050 | loss 0.7510\n",
            "Train: epoch 0002 / 0020 | batch 0048 / 0050 | loss 0.7505\n",
            "Train: epoch 0002 / 0020 | batch 0049 / 0050 | loss 0.7499\n",
            "Val loss 0.1069\n",
            "Dice score : 10.008166313171387\n",
            "Val loss 0.1102\n",
            "Dice score : 17.185359954833984\n",
            "Val loss 0.1120\n",
            "Dice score : 34.025840759277344\n",
            "Val loss 0.1107\n",
            "Dice score : 20.826934814453125\n",
            "Val loss 0.1089\n",
            "Dice score : 38.43523025512695\n",
            "Val loss 0.1067\n",
            "Dice score : 65.3386001586914\n",
            "Val loss 0.1082\n",
            "Dice score : 75.60546112060547\n",
            "Val loss 0.1081\n",
            "Dice score : 73.93749237060547\n",
            "Val loss 0.1078\n",
            "Dice score : 80.47174835205078\n",
            "Val loss 0.1063\n",
            "Dice score : 124.01765441894531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [02:32<22:51, 76.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0003 / 0020 | batch 0000 / 0050 | loss 0.7231\n",
            "Train: epoch 0003 / 0020 | batch 0001 / 0050 | loss 0.7229\n",
            "Train: epoch 0003 / 0020 | batch 0002 / 0050 | loss 0.7225\n",
            "Train: epoch 0003 / 0020 | batch 0003 / 0050 | loss 0.7221\n",
            "Train: epoch 0003 / 0020 | batch 0004 / 0050 | loss 0.7218\n",
            "Train: epoch 0003 / 0020 | batch 0005 / 0050 | loss 0.7215\n",
            "Train: epoch 0003 / 0020 | batch 0006 / 0050 | loss 0.7212\n",
            "Train: epoch 0003 / 0020 | batch 0007 / 0050 | loss 0.7209\n",
            "Train: epoch 0003 / 0020 | batch 0008 / 0050 | loss 0.7206\n",
            "Train: epoch 0003 / 0020 | batch 0009 / 0050 | loss 0.7203\n",
            "Train: epoch 0003 / 0020 | batch 0010 / 0050 | loss 0.7200\n",
            "Train: epoch 0003 / 0020 | batch 0011 / 0050 | loss 0.7198\n",
            "Train: epoch 0003 / 0020 | batch 0012 / 0050 | loss 0.7196\n",
            "Train: epoch 0003 / 0020 | batch 0013 / 0050 | loss 0.7193\n",
            "Train: epoch 0003 / 0020 | batch 0014 / 0050 | loss 0.7191\n",
            "Train: epoch 0003 / 0020 | batch 0015 / 0050 | loss 0.7188\n",
            "Train: epoch 0003 / 0020 | batch 0016 / 0050 | loss 0.7187\n",
            "Train: epoch 0003 / 0020 | batch 0017 / 0050 | loss 0.7184\n",
            "Train: epoch 0003 / 0020 | batch 0018 / 0050 | loss 0.7182\n",
            "Train: epoch 0003 / 0020 | batch 0019 / 0050 | loss 0.7180\n",
            "Train: epoch 0003 / 0020 | batch 0020 / 0050 | loss 0.7178\n",
            "Train: epoch 0003 / 0020 | batch 0021 / 0050 | loss 0.7176\n",
            "Train: epoch 0003 / 0020 | batch 0022 / 0050 | loss 0.7173\n",
            "Train: epoch 0003 / 0020 | batch 0023 / 0050 | loss 0.7171\n",
            "Train: epoch 0003 / 0020 | batch 0024 / 0050 | loss 0.7169\n",
            "Train: epoch 0003 / 0020 | batch 0025 / 0050 | loss 0.7167\n",
            "Train: epoch 0003 / 0020 | batch 0026 / 0050 | loss 0.7165\n",
            "Train: epoch 0003 / 0020 | batch 0027 / 0050 | loss 0.7163\n",
            "Train: epoch 0003 / 0020 | batch 0028 / 0050 | loss 0.7161\n",
            "Train: epoch 0003 / 0020 | batch 0029 / 0050 | loss 0.7159\n",
            "Train: epoch 0003 / 0020 | batch 0030 / 0050 | loss 0.7157\n",
            "Train: epoch 0003 / 0020 | batch 0031 / 0050 | loss 0.7155\n",
            "Train: epoch 0003 / 0020 | batch 0032 / 0050 | loss 0.7154\n",
            "Train: epoch 0003 / 0020 | batch 0033 / 0050 | loss 0.7152\n",
            "Train: epoch 0003 / 0020 | batch 0034 / 0050 | loss 0.7150\n",
            "Train: epoch 0003 / 0020 | batch 0035 / 0050 | loss 0.7148\n",
            "Train: epoch 0003 / 0020 | batch 0036 / 0050 | loss 0.7147\n",
            "Train: epoch 0003 / 0020 | batch 0037 / 0050 | loss 0.7145\n",
            "Train: epoch 0003 / 0020 | batch 0038 / 0050 | loss 0.7143\n",
            "Train: epoch 0003 / 0020 | batch 0039 / 0050 | loss 0.7142\n",
            "Train: epoch 0003 / 0020 | batch 0040 / 0050 | loss 0.7140\n",
            "Train: epoch 0003 / 0020 | batch 0041 / 0050 | loss 0.7139\n",
            "Train: epoch 0003 / 0020 | batch 0042 / 0050 | loss 0.7137\n",
            "Train: epoch 0003 / 0020 | batch 0043 / 0050 | loss 0.7136\n",
            "Train: epoch 0003 / 0020 | batch 0044 / 0050 | loss 0.7134\n",
            "Train: epoch 0003 / 0020 | batch 0045 / 0050 | loss 0.7133\n",
            "Train: epoch 0003 / 0020 | batch 0046 / 0050 | loss 0.7131\n",
            "Train: epoch 0003 / 0020 | batch 0047 / 0050 | loss 0.7130\n",
            "Train: epoch 0003 / 0020 | batch 0048 / 0050 | loss 0.7128\n",
            "Train: epoch 0003 / 0020 | batch 0049 / 0050 | loss 0.7127\n",
            "Val loss 0.0667\n",
            "Dice score : 10.950244903564453\n",
            "Val loss 0.0835\n",
            "Dice score : 24.461301803588867\n",
            "Val loss 0.0728\n",
            "Dice score : 40.91782760620117\n",
            "Val loss 0.0735\n",
            "Dice score : 39.38422775268555\n",
            "Val loss 0.0703\n",
            "Dice score : 31.488574981689453\n",
            "Val loss 0.0688\n",
            "Dice score : 62.05539321899414\n",
            "Val loss 0.0674\n",
            "Dice score : 90.30007934570312\n",
            "Val loss 0.0668\n",
            "Dice score : 68.32119750976562\n",
            "Val loss 0.0665\n",
            "Dice score : 79.41767883300781\n",
            "Val loss 0.0667\n",
            "Dice score : 94.87610626220703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [03:48<21:36, 76.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0004 / 0020 | batch 0000 / 0050 | loss 0.7054\n",
            "Train: epoch 0004 / 0020 | batch 0001 / 0050 | loss 0.7054\n",
            "Train: epoch 0004 / 0020 | batch 0002 / 0050 | loss 0.7054\n",
            "Train: epoch 0004 / 0020 | batch 0003 / 0050 | loss 0.7053\n",
            "Train: epoch 0004 / 0020 | batch 0004 / 0050 | loss 0.7053\n",
            "Train: epoch 0004 / 0020 | batch 0005 / 0050 | loss 0.7052\n",
            "Train: epoch 0004 / 0020 | batch 0006 / 0050 | loss 0.7051\n",
            "Train: epoch 0004 / 0020 | batch 0007 / 0050 | loss 0.7050\n",
            "Train: epoch 0004 / 0020 | batch 0008 / 0050 | loss 0.7050\n",
            "Train: epoch 0004 / 0020 | batch 0009 / 0050 | loss 0.7049\n",
            "Train: epoch 0004 / 0020 | batch 0010 / 0050 | loss 0.7048\n",
            "Train: epoch 0004 / 0020 | batch 0011 / 0050 | loss 0.7047\n",
            "Train: epoch 0004 / 0020 | batch 0012 / 0050 | loss 0.7047\n",
            "Train: epoch 0004 / 0020 | batch 0013 / 0050 | loss 0.7046\n",
            "Train: epoch 0004 / 0020 | batch 0014 / 0050 | loss 0.7045\n",
            "Train: epoch 0004 / 0020 | batch 0015 / 0050 | loss 0.7045\n",
            "Train: epoch 0004 / 0020 | batch 0016 / 0050 | loss 0.7044\n",
            "Train: epoch 0004 / 0020 | batch 0017 / 0050 | loss 0.7043\n",
            "Train: epoch 0004 / 0020 | batch 0018 / 0050 | loss 0.7043\n",
            "Train: epoch 0004 / 0020 | batch 0019 / 0050 | loss 0.7042\n",
            "Train: epoch 0004 / 0020 | batch 0020 / 0050 | loss 0.7041\n",
            "Train: epoch 0004 / 0020 | batch 0021 / 0050 | loss 0.7041\n",
            "Train: epoch 0004 / 0020 | batch 0022 / 0050 | loss 0.7040\n",
            "Train: epoch 0004 / 0020 | batch 0023 / 0050 | loss 0.7039\n",
            "Train: epoch 0004 / 0020 | batch 0024 / 0050 | loss 0.7039\n",
            "Train: epoch 0004 / 0020 | batch 0025 / 0050 | loss 0.7038\n",
            "Train: epoch 0004 / 0020 | batch 0026 / 0050 | loss 0.7037\n",
            "Train: epoch 0004 / 0020 | batch 0027 / 0050 | loss 0.7037\n",
            "Train: epoch 0004 / 0020 | batch 0028 / 0050 | loss 0.7036\n",
            "Train: epoch 0004 / 0020 | batch 0029 / 0050 | loss 0.7035\n",
            "Train: epoch 0004 / 0020 | batch 0030 / 0050 | loss 0.7035\n",
            "Train: epoch 0004 / 0020 | batch 0031 / 0050 | loss 0.7034\n",
            "Train: epoch 0004 / 0020 | batch 0032 / 0050 | loss 0.7034\n",
            "Train: epoch 0004 / 0020 | batch 0033 / 0050 | loss 0.7033\n",
            "Train: epoch 0004 / 0020 | batch 0034 / 0050 | loss 0.7033\n",
            "Train: epoch 0004 / 0020 | batch 0035 / 0050 | loss 0.7032\n",
            "Train: epoch 0004 / 0020 | batch 0036 / 0050 | loss 0.7031\n",
            "Train: epoch 0004 / 0020 | batch 0037 / 0050 | loss 0.7031\n",
            "Train: epoch 0004 / 0020 | batch 0038 / 0050 | loss 0.7030\n",
            "Train: epoch 0004 / 0020 | batch 0039 / 0050 | loss 0.7030\n",
            "Train: epoch 0004 / 0020 | batch 0040 / 0050 | loss 0.7029\n",
            "Train: epoch 0004 / 0020 | batch 0041 / 0050 | loss 0.7029\n",
            "Train: epoch 0004 / 0020 | batch 0042 / 0050 | loss 0.7028\n",
            "Train: epoch 0004 / 0020 | batch 0043 / 0050 | loss 0.7028\n",
            "Train: epoch 0004 / 0020 | batch 0044 / 0050 | loss 0.7027\n",
            "Train: epoch 0004 / 0020 | batch 0045 / 0050 | loss 0.7027\n",
            "Train: epoch 0004 / 0020 | batch 0046 / 0050 | loss 0.7026\n",
            "Train: epoch 0004 / 0020 | batch 0047 / 0050 | loss 0.7026\n",
            "Train: epoch 0004 / 0020 | batch 0048 / 0050 | loss 0.7025\n",
            "Train: epoch 0004 / 0020 | batch 0049 / 0050 | loss 0.7025\n",
            "Val loss 0.0577\n",
            "Dice score : 4.662168025970459\n",
            "Val loss 0.0544\n",
            "Dice score : 13.857908248901367\n",
            "Val loss 0.0638\n",
            "Dice score : 27.93659210205078\n",
            "Val loss 0.0601\n",
            "Dice score : 44.29570770263672\n",
            "Val loss 0.0619\n",
            "Dice score : 40.84403991699219\n",
            "Val loss 0.0663\n",
            "Dice score : 55.487796783447266\n",
            "Val loss 0.0634\n",
            "Dice score : 62.96111297607422\n",
            "Val loss 0.0619\n",
            "Dice score : 49.91647720336914\n",
            "Val loss 0.0617\n",
            "Dice score : 83.4848861694336\n",
            "Val loss 0.0609\n",
            "Dice score : 67.42432403564453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [05:04<20:19, 76.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0005 / 0020 | batch 0000 / 0050 | loss 0.7000\n",
            "Train: epoch 0005 / 0020 | batch 0001 / 0050 | loss 0.7001\n",
            "Train: epoch 0005 / 0020 | batch 0002 / 0050 | loss 0.7001\n",
            "Train: epoch 0005 / 0020 | batch 0003 / 0050 | loss 0.7000\n",
            "Train: epoch 0005 / 0020 | batch 0004 / 0050 | loss 0.7000\n",
            "Train: epoch 0005 / 0020 | batch 0005 / 0050 | loss 0.6999\n",
            "Train: epoch 0005 / 0020 | batch 0006 / 0050 | loss 0.6999\n",
            "Train: epoch 0005 / 0020 | batch 0007 / 0050 | loss 0.6998\n",
            "Train: epoch 0005 / 0020 | batch 0008 / 0050 | loss 0.6998\n",
            "Train: epoch 0005 / 0020 | batch 0009 / 0050 | loss 0.6998\n",
            "Train: epoch 0005 / 0020 | batch 0010 / 0050 | loss 0.6997\n",
            "Train: epoch 0005 / 0020 | batch 0011 / 0050 | loss 0.6997\n",
            "Train: epoch 0005 / 0020 | batch 0012 / 0050 | loss 0.6997\n",
            "Train: epoch 0005 / 0020 | batch 0013 / 0050 | loss 0.6996\n",
            "Train: epoch 0005 / 0020 | batch 0014 / 0050 | loss 0.6996\n",
            "Train: epoch 0005 / 0020 | batch 0015 / 0050 | loss 0.6996\n",
            "Train: epoch 0005 / 0020 | batch 0016 / 0050 | loss 0.6995\n",
            "Train: epoch 0005 / 0020 | batch 0017 / 0050 | loss 0.6995\n",
            "Train: epoch 0005 / 0020 | batch 0018 / 0050 | loss 0.6995\n",
            "Train: epoch 0005 / 0020 | batch 0019 / 0050 | loss 0.6994\n",
            "Train: epoch 0005 / 0020 | batch 0020 / 0050 | loss 0.6994\n",
            "Train: epoch 0005 / 0020 | batch 0021 / 0050 | loss 0.6994\n",
            "Train: epoch 0005 / 0020 | batch 0022 / 0050 | loss 0.6994\n",
            "Train: epoch 0005 / 0020 | batch 0023 / 0050 | loss 0.6993\n",
            "Train: epoch 0005 / 0020 | batch 0024 / 0050 | loss 0.6993\n",
            "Train: epoch 0005 / 0020 | batch 0025 / 0050 | loss 0.6993\n",
            "Train: epoch 0005 / 0020 | batch 0026 / 0050 | loss 0.6993\n",
            "Train: epoch 0005 / 0020 | batch 0027 / 0050 | loss 0.6992\n",
            "Train: epoch 0005 / 0020 | batch 0028 / 0050 | loss 0.6992\n",
            "Train: epoch 0005 / 0020 | batch 0029 / 0050 | loss 0.6992\n",
            "Train: epoch 0005 / 0020 | batch 0030 / 0050 | loss 0.6992\n",
            "Train: epoch 0005 / 0020 | batch 0031 / 0050 | loss 0.6991\n",
            "Train: epoch 0005 / 0020 | batch 0032 / 0050 | loss 0.6991\n",
            "Train: epoch 0005 / 0020 | batch 0033 / 0050 | loss 0.6991\n",
            "Train: epoch 0005 / 0020 | batch 0034 / 0050 | loss 0.6991\n",
            "Train: epoch 0005 / 0020 | batch 0035 / 0050 | loss 0.6990\n",
            "Train: epoch 0005 / 0020 | batch 0036 / 0050 | loss 0.6990\n",
            "Train: epoch 0005 / 0020 | batch 0037 / 0050 | loss 0.6990\n",
            "Train: epoch 0005 / 0020 | batch 0038 / 0050 | loss 0.6990\n",
            "Train: epoch 0005 / 0020 | batch 0039 / 0050 | loss 0.6989\n",
            "Train: epoch 0005 / 0020 | batch 0040 / 0050 | loss 0.6989\n",
            "Train: epoch 0005 / 0020 | batch 0041 / 0050 | loss 0.6989\n",
            "Train: epoch 0005 / 0020 | batch 0042 / 0050 | loss 0.6989\n",
            "Train: epoch 0005 / 0020 | batch 0043 / 0050 | loss 0.6988\n",
            "Train: epoch 0005 / 0020 | batch 0044 / 0050 | loss 0.6988\n",
            "Train: epoch 0005 / 0020 | batch 0045 / 0050 | loss 0.6988\n",
            "Train: epoch 0005 / 0020 | batch 0046 / 0050 | loss 0.6988\n",
            "Train: epoch 0005 / 0020 | batch 0047 / 0050 | loss 0.6987\n",
            "Train: epoch 0005 / 0020 | batch 0048 / 0050 | loss 0.6987\n",
            "Train: epoch 0005 / 0020 | batch 0049 / 0050 | loss 0.6987\n",
            "Val loss 0.0657\n",
            "Dice score : 4.660356044769287\n",
            "Val loss 0.0610\n",
            "Dice score : 14.16575813293457\n",
            "Val loss 0.0682\n",
            "Dice score : 20.575305938720703\n",
            "Val loss 0.0636\n",
            "Dice score : 23.154489517211914\n",
            "Val loss 0.0592\n",
            "Dice score : 31.426916122436523\n",
            "Val loss 0.0591\n",
            "Dice score : 53.07242965698242\n",
            "Val loss 0.0610\n",
            "Dice score : 37.66609191894531\n",
            "Val loss 0.0612\n",
            "Dice score : 39.67464065551758\n",
            "Val loss 0.0623\n",
            "Dice score : 40.773529052734375\n",
            "Val loss 0.0606\n",
            "Dice score : 64.0776596069336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [06:22<19:10, 76.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0006 / 0020 | batch 0000 / 0050 | loss 0.6975\n",
            "Train: epoch 0006 / 0020 | batch 0001 / 0050 | loss 0.6975\n",
            "Train: epoch 0006 / 0020 | batch 0002 / 0050 | loss 0.6975\n",
            "Train: epoch 0006 / 0020 | batch 0003 / 0050 | loss 0.6975\n",
            "Train: epoch 0006 / 0020 | batch 0004 / 0050 | loss 0.6975\n",
            "Train: epoch 0006 / 0020 | batch 0005 / 0050 | loss 0.6974\n",
            "Train: epoch 0006 / 0020 | batch 0006 / 0050 | loss 0.6974\n",
            "Train: epoch 0006 / 0020 | batch 0007 / 0050 | loss 0.6974\n",
            "Train: epoch 0006 / 0020 | batch 0008 / 0050 | loss 0.6974\n",
            "Train: epoch 0006 / 0020 | batch 0009 / 0050 | loss 0.6974\n",
            "Train: epoch 0006 / 0020 | batch 0010 / 0050 | loss 0.6974\n",
            "Train: epoch 0006 / 0020 | batch 0011 / 0050 | loss 0.6974\n",
            "Train: epoch 0006 / 0020 | batch 0012 / 0050 | loss 0.6973\n",
            "Train: epoch 0006 / 0020 | batch 0013 / 0050 | loss 0.6973\n",
            "Train: epoch 0006 / 0020 | batch 0014 / 0050 | loss 0.6973\n",
            "Train: epoch 0006 / 0020 | batch 0015 / 0050 | loss 0.6973\n",
            "Train: epoch 0006 / 0020 | batch 0016 / 0050 | loss 0.6973\n",
            "Train: epoch 0006 / 0020 | batch 0017 / 0050 | loss 0.6973\n",
            "Train: epoch 0006 / 0020 | batch 0018 / 0050 | loss 0.6972\n",
            "Train: epoch 0006 / 0020 | batch 0019 / 0050 | loss 0.6972\n",
            "Train: epoch 0006 / 0020 | batch 0020 / 0050 | loss 0.6972\n",
            "Train: epoch 0006 / 0020 | batch 0021 / 0050 | loss 0.6972\n",
            "Train: epoch 0006 / 0020 | batch 0022 / 0050 | loss 0.6972\n",
            "Train: epoch 0006 / 0020 | batch 0023 / 0050 | loss 0.6972\n",
            "Train: epoch 0006 / 0020 | batch 0024 / 0050 | loss 0.6972\n",
            "Train: epoch 0006 / 0020 | batch 0025 / 0050 | loss 0.6971\n",
            "Train: epoch 0006 / 0020 | batch 0026 / 0050 | loss 0.6971\n",
            "Train: epoch 0006 / 0020 | batch 0027 / 0050 | loss 0.6971\n",
            "Train: epoch 0006 / 0020 | batch 0028 / 0050 | loss 0.6971\n",
            "Train: epoch 0006 / 0020 | batch 0029 / 0050 | loss 0.6971\n",
            "Train: epoch 0006 / 0020 | batch 0030 / 0050 | loss 0.6971\n",
            "Train: epoch 0006 / 0020 | batch 0031 / 0050 | loss 0.6971\n",
            "Train: epoch 0006 / 0020 | batch 0032 / 0050 | loss 0.6970\n",
            "Train: epoch 0006 / 0020 | batch 0033 / 0050 | loss 0.6970\n",
            "Train: epoch 0006 / 0020 | batch 0034 / 0050 | loss 0.6970\n",
            "Train: epoch 0006 / 0020 | batch 0035 / 0050 | loss 0.6970\n",
            "Train: epoch 0006 / 0020 | batch 0036 / 0050 | loss 0.6970\n",
            "Train: epoch 0006 / 0020 | batch 0037 / 0050 | loss 0.6970\n",
            "Train: epoch 0006 / 0020 | batch 0038 / 0050 | loss 0.6969\n",
            "Train: epoch 0006 / 0020 | batch 0039 / 0050 | loss 0.6969\n",
            "Train: epoch 0006 / 0020 | batch 0040 / 0050 | loss 0.6969\n",
            "Train: epoch 0006 / 0020 | batch 0041 / 0050 | loss 0.6969\n",
            "Train: epoch 0006 / 0020 | batch 0042 / 0050 | loss 0.6969\n",
            "Train: epoch 0006 / 0020 | batch 0043 / 0050 | loss 0.6969\n",
            "Train: epoch 0006 / 0020 | batch 0044 / 0050 | loss 0.6969\n",
            "Train: epoch 0006 / 0020 | batch 0045 / 0050 | loss 0.6969\n",
            "Train: epoch 0006 / 0020 | batch 0046 / 0050 | loss 0.6968\n",
            "Train: epoch 0006 / 0020 | batch 0047 / 0050 | loss 0.6968\n",
            "Train: epoch 0006 / 0020 | batch 0048 / 0050 | loss 0.6968\n",
            "Train: epoch 0006 / 0020 | batch 0049 / 0050 | loss 0.6968\n",
            "Val loss 0.0483\n",
            "Dice score : 24.623619079589844\n",
            "Val loss 0.0490\n",
            "Dice score : 31.25161361694336\n",
            "Val loss 0.0584\n",
            "Dice score : 24.288047790527344\n",
            "Val loss 0.0583\n",
            "Dice score : 55.94707489013672\n",
            "Val loss 0.0608\n",
            "Dice score : 69.98454284667969\n",
            "Val loss 0.0605\n",
            "Dice score : 84.73919677734375\n",
            "Val loss 0.0607\n",
            "Dice score : 118.91159057617188\n",
            "Val loss 0.0588\n",
            "Dice score : 98.6469955444336\n",
            "Val loss 0.0626\n",
            "Dice score : 175.82408142089844\n",
            "Val loss 0.0620\n",
            "Dice score : 79.6822280883789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [07:39<17:55, 76.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0007 / 0020 | batch 0000 / 0050 | loss 0.6961\n",
            "Train: epoch 0007 / 0020 | batch 0001 / 0050 | loss 0.6961\n",
            "Train: epoch 0007 / 0020 | batch 0002 / 0050 | loss 0.6961\n",
            "Train: epoch 0007 / 0020 | batch 0003 / 0050 | loss 0.6961\n",
            "Train: epoch 0007 / 0020 | batch 0004 / 0050 | loss 0.6961\n",
            "Train: epoch 0007 / 0020 | batch 0005 / 0050 | loss 0.6961\n",
            "Train: epoch 0007 / 0020 | batch 0006 / 0050 | loss 0.6961\n",
            "Train: epoch 0007 / 0020 | batch 0007 / 0050 | loss 0.6961\n",
            "Train: epoch 0007 / 0020 | batch 0008 / 0050 | loss 0.6961\n",
            "Train: epoch 0007 / 0020 | batch 0009 / 0050 | loss 0.6961\n",
            "Train: epoch 0007 / 0020 | batch 0010 / 0050 | loss 0.6961\n",
            "Train: epoch 0007 / 0020 | batch 0011 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0012 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0013 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0014 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0015 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0016 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0017 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0018 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0019 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0020 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0021 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0022 / 0050 | loss 0.6960\n",
            "Train: epoch 0007 / 0020 | batch 0023 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0024 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0025 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0026 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0027 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0028 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0029 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0030 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0031 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0032 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0033 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0034 / 0050 | loss 0.6959\n",
            "Train: epoch 0007 / 0020 | batch 0035 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0036 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0037 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0038 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0039 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0040 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0041 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0042 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0043 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0044 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0045 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0046 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0047 / 0050 | loss 0.6958\n",
            "Train: epoch 0007 / 0020 | batch 0048 / 0050 | loss 0.6957\n",
            "Train: epoch 0007 / 0020 | batch 0049 / 0050 | loss 0.6957\n",
            "Val loss 0.0569\n",
            "Dice score : 14.221270561218262\n",
            "Val loss 0.0582\n",
            "Dice score : 28.361948013305664\n",
            "Val loss 0.0530\n",
            "Dice score : 55.24940490722656\n",
            "Val loss 0.0583\n",
            "Dice score : 57.62437057495117\n",
            "Val loss 0.0562\n",
            "Dice score : 55.87982940673828\n",
            "Val loss 0.0580\n",
            "Dice score : 151.0186004638672\n",
            "Val loss 0.0581\n",
            "Dice score : 72.1070785522461\n",
            "Val loss 0.0572\n",
            "Dice score : 119.02587127685547\n",
            "Val loss 0.0616\n",
            "Dice score : 107.28958129882812\n",
            "Val loss 0.0633\n",
            "Dice score : 224.3258514404297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [08:55<16:34, 76.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0008 / 0020 | batch 0000 / 0050 | loss 0.6954\n",
            "Train: epoch 0008 / 0020 | batch 0001 / 0050 | loss 0.6954\n",
            "Train: epoch 0008 / 0020 | batch 0002 / 0050 | loss 0.6954\n",
            "Train: epoch 0008 / 0020 | batch 0003 / 0050 | loss 0.6954\n",
            "Train: epoch 0008 / 0020 | batch 0004 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0005 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0006 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0007 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0008 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0009 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0010 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0011 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0012 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0013 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0014 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0015 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0016 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0017 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0018 / 0050 | loss 0.6953\n",
            "Train: epoch 0008 / 0020 | batch 0019 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0020 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0021 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0022 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0023 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0024 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0025 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0026 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0027 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0028 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0029 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0030 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0031 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0032 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0033 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0034 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0035 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0036 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0037 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0038 / 0050 | loss 0.6952\n",
            "Train: epoch 0008 / 0020 | batch 0039 / 0050 | loss 0.6951\n",
            "Train: epoch 0008 / 0020 | batch 0040 / 0050 | loss 0.6951\n",
            "Train: epoch 0008 / 0020 | batch 0041 / 0050 | loss 0.6951\n",
            "Train: epoch 0008 / 0020 | batch 0042 / 0050 | loss 0.6951\n",
            "Train: epoch 0008 / 0020 | batch 0043 / 0050 | loss 0.6951\n",
            "Train: epoch 0008 / 0020 | batch 0044 / 0050 | loss 0.6951\n",
            "Train: epoch 0008 / 0020 | batch 0045 / 0050 | loss 0.6951\n",
            "Train: epoch 0008 / 0020 | batch 0046 / 0050 | loss 0.6951\n",
            "Train: epoch 0008 / 0020 | batch 0047 / 0050 | loss 0.6951\n",
            "Train: epoch 0008 / 0020 | batch 0048 / 0050 | loss 0.6951\n",
            "Train: epoch 0008 / 0020 | batch 0049 / 0050 | loss 0.6951\n",
            "Val loss 0.0733\n",
            "Dice score : 20.313919067382812\n",
            "Val loss 0.0664\n",
            "Dice score : 34.51787567138672\n",
            "Val loss 0.0718\n",
            "Dice score : 52.37760543823242\n",
            "Val loss 0.0672\n",
            "Dice score : 98.47109985351562\n",
            "Val loss 0.0636\n",
            "Dice score : 108.9046401977539\n",
            "Val loss 0.0641\n",
            "Dice score : 141.2027587890625\n",
            "Val loss 0.0632\n",
            "Dice score : 84.7816162109375\n",
            "Val loss 0.0641\n",
            "Dice score : 205.08567810058594\n",
            "Val loss 0.0669\n",
            "Dice score : 165.1969757080078\n",
            "Val loss 0.0656\n",
            "Dice score : 216.8197021484375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [10:10<15:13, 76.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0009 / 0020 | batch 0000 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0001 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0002 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0003 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0004 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0005 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0006 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0007 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0008 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0009 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0010 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0011 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0012 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0013 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0014 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0015 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0016 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0017 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0018 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0019 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0020 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0021 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0022 / 0050 | loss 0.6948\n",
            "Train: epoch 0009 / 0020 | batch 0023 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0024 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0025 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0026 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0027 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0028 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0029 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0030 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0031 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0032 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0033 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0034 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0035 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0036 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0037 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0038 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0039 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0040 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0041 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0042 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0043 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0044 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0045 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0046 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0047 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0048 / 0050 | loss 0.6947\n",
            "Train: epoch 0009 / 0020 | batch 0049 / 0050 | loss 0.6947\n",
            "Val loss 0.0720\n",
            "Dice score : 7.023644924163818\n",
            "Val loss 0.0756\n",
            "Dice score : 19.020448684692383\n",
            "Val loss 0.0775\n",
            "Dice score : 47.32929611206055\n",
            "Val loss 0.0740\n",
            "Dice score : 65.0778579711914\n",
            "Val loss 0.0685\n",
            "Dice score : 56.45528793334961\n",
            "Val loss 0.0677\n",
            "Dice score : 68.5296630859375\n",
            "Val loss 0.0649\n",
            "Dice score : 129.50160217285156\n",
            "Val loss 0.0692\n",
            "Dice score : 134.9813995361328\n",
            "Val loss 0.0689\n",
            "Dice score : 90.83604431152344\n",
            "Val loss 0.0671\n",
            "Dice score : 123.01173400878906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [11:24<13:50, 75.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0010 / 0020 | batch 0000 / 0050 | loss 0.6946\n",
            "Train: epoch 0010 / 0020 | batch 0001 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0002 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0003 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0004 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0005 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0006 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0007 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0008 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0009 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0010 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0011 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0012 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0013 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0014 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0015 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0016 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0017 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0018 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0019 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0020 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0021 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0022 / 0050 | loss 0.6945\n",
            "Train: epoch 0010 / 0020 | batch 0023 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0024 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0025 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0026 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0027 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0028 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0029 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0030 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0031 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0032 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0033 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0034 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0035 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0036 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0037 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0038 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0039 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0040 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0041 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0042 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0043 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0044 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0045 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0046 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0047 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0048 / 0050 | loss 0.6944\n",
            "Train: epoch 0010 / 0020 | batch 0049 / 0050 | loss 0.6944\n",
            "Val loss 0.0614\n",
            "Dice score : 21.561229705810547\n",
            "Val loss 0.0756\n",
            "Dice score : 49.15760040283203\n",
            "Val loss 0.0806\n",
            "Dice score : 55.886871337890625\n",
            "Val loss 0.0768\n",
            "Dice score : 50.32657241821289\n",
            "Val loss 0.0730\n",
            "Dice score : 110.95406341552734\n",
            "Val loss 0.0684\n",
            "Dice score : 59.68027114868164\n",
            "Val loss 0.0720\n",
            "Dice score : 67.1114501953125\n",
            "Val loss 0.0693\n",
            "Dice score : 181.13409423828125\n",
            "Val loss 0.0699\n",
            "Dice score : 112.58126068115234\n",
            "Val loss 0.0688\n",
            "Dice score : 253.77215576171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [12:41<12:39, 75.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0011 / 0020 | batch 0000 / 0050 | loss 0.6944\n",
            "Train: epoch 0011 / 0020 | batch 0001 / 0050 | loss 0.6943\n",
            "Train: epoch 0011 / 0020 | batch 0002 / 0050 | loss 0.6943\n",
            "Train: epoch 0011 / 0020 | batch 0003 / 0050 | loss 0.6943\n",
            "Train: epoch 0011 / 0020 | batch 0004 / 0050 | loss 0.6943\n",
            "Train: epoch 0011 / 0020 | batch 0005 / 0050 | loss 0.6943\n",
            "Train: epoch 0011 / 0020 | batch 0006 / 0050 | loss 0.6942\n",
            "Train: epoch 0011 / 0020 | batch 0007 / 0050 | loss 0.6942\n",
            "Train: epoch 0011 / 0020 | batch 0008 / 0050 | loss 0.6942\n",
            "Train: epoch 0011 / 0020 | batch 0009 / 0050 | loss 0.6942\n",
            "Train: epoch 0011 / 0020 | batch 0010 / 0050 | loss 0.6942\n",
            "Train: epoch 0011 / 0020 | batch 0011 / 0050 | loss 0.6942\n",
            "Train: epoch 0011 / 0020 | batch 0012 / 0050 | loss 0.6942\n",
            "Train: epoch 0011 / 0020 | batch 0013 / 0050 | loss 0.6942\n",
            "Train: epoch 0011 / 0020 | batch 0014 / 0050 | loss 0.6942\n",
            "Train: epoch 0011 / 0020 | batch 0015 / 0050 | loss 0.6942\n",
            "Train: epoch 0011 / 0020 | batch 0016 / 0050 | loss 0.6942\n",
            "Train: epoch 0011 / 0020 | batch 0017 / 0050 | loss 0.6942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [13:09<13:09, 78.97s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7bfb0f01cae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSpine_segment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer_Spine_segment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpine_segment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer_Spine_segment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-cb3d894dd924>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, validation_loader)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#output:prediction, label: answer tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Dataset(data_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/test' , transform = transform_testset)\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers = 8)\n",
        "\n",
        "trainer_Spine_segment.test(test_loader)"
      ],
      "metadata": {
        "id": "XHIR53bc3-Q3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "efd7eaff-e9c2-49a5-c27d-e8c5ca1e96da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['151.dcm', '152.dcm', '153.dcm', '154.dcm', '155.dcm', '156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3052, 2140)\n",
            "(6, 1024, 1024)\n",
            "(1024, 1024)\n",
            "1.0\n",
            "(3052, 2140, 7)\n",
            "2\n",
            "3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0329c28202cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer_Spine_segment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-8eff6978abac>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (6,1024,1024)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                     \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'clone'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_net = UNET()\n",
        "train_net.cuda()\n",
        "\n",
        "optim = torch.optim.Adam(train_net.parameters(), lr = 0.0001)\n",
        "train_net, optim, start_epoch = load(ckpt_dir = ckpt_dir, net = train_net, optim = optim) # 저장된 네트워크 불러오기\n",
        "\n",
        "train_trainer_Spine_segment = trainer(train_net, train_loader,\"Adam\", epoch_size=30, learning_rate=0.0001)\n",
        "\n",
        "train_trainer_Spine_segment.train(val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkqyl-khi2OI",
        "outputId": "b43de97b-1766-42ed-b2af-02b98860a0b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0001 / 0030 | batch 0000 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0001 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0002 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0003 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0004 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0005 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0006 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0007 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0008 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0009 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0010 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0011 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0012 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0013 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0014 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0015 / 0050 | loss 0.6945\n",
            "Train: epoch 0001 / 0030 | batch 0016 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0017 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0018 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0019 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0020 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0021 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0022 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0023 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0024 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0025 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0026 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0027 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0028 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0029 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0030 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0031 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0032 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0033 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0034 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0035 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0036 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0037 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0038 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0039 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0040 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0041 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0042 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0043 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0044 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0045 / 0050 | loss 0.6944\n",
            "Train: epoch 0001 / 0030 | batch 0046 / 0050 | loss 0.6943\n",
            "Train: epoch 0001 / 0030 | batch 0047 / 0050 | loss 0.6943\n",
            "Train: epoch 0001 / 0030 | batch 0048 / 0050 | loss 0.6943\n",
            "Train: epoch 0001 / 0030 | batch 0049 / 0050 | loss 0.6943\n",
            "Val loss 0.0688\n",
            "Dice score : 12.05640983581543\n",
            "Val loss 0.0753\n",
            "Dice score : 27.216699600219727\n",
            "Val loss 0.0696\n",
            "Dice score : 36.39410400390625\n",
            "Val loss 0.0703\n",
            "Dice score : 46.039615631103516\n",
            "Val loss 0.0661\n",
            "Dice score : 62.433040618896484\n",
            "Val loss 0.0642\n",
            "Dice score : 74.27042388916016\n",
            "Val loss 0.0643\n",
            "Dice score : 104.42676544189453\n",
            "Val loss 0.0705\n",
            "Dice score : 115.89508819580078\n",
            "Val loss 0.0697\n",
            "Dice score : 66.87895965576172\n",
            "Val loss 0.0692\n",
            "Dice score : 88.48725891113281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 1/30 [01:16<37:01, 76.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0002 / 0030 | batch 0000 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0001 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0002 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0003 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0004 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0005 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0006 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0007 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0008 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0009 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0010 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0011 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0012 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0013 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0014 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0015 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0016 / 0050 | loss 0.6942\n",
            "Train: epoch 0002 / 0030 | batch 0017 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0018 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0019 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0020 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0021 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0022 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0023 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0024 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0025 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0026 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0027 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0028 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0029 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0030 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0031 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0032 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0033 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0034 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0035 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0036 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0037 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0038 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0039 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0040 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0041 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0042 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0043 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0044 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0045 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0046 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0047 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0048 / 0050 | loss 0.6941\n",
            "Train: epoch 0002 / 0030 | batch 0049 / 0050 | loss 0.6941\n",
            "Val loss 0.0850\n",
            "Dice score : 10.496405601501465\n",
            "Val loss 0.0789\n",
            "Dice score : 22.466726303100586\n",
            "Val loss 0.0728\n",
            "Dice score : 46.67365646362305\n",
            "Val loss 0.0671\n",
            "Dice score : 56.329986572265625\n",
            "Val loss 0.0730\n",
            "Dice score : 71.34892272949219\n",
            "Val loss 0.0730\n",
            "Dice score : 67.48795318603516\n",
            "Val loss 0.0698\n",
            "Dice score : 36.82665252685547\n",
            "Val loss 0.0713\n",
            "Dice score : 41.91761779785156\n",
            "Val loss 0.0729\n",
            "Dice score : 57.054595947265625\n",
            "Val loss 0.0711\n",
            "Dice score : 55.02729415893555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 2/30 [02:34<36:02, 77.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0003 / 0030 | batch 0000 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0001 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0002 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0003 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0004 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0005 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0006 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0007 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0008 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0009 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0010 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0011 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0012 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0013 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0014 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0015 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0016 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0017 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0018 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0019 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0020 / 0050 | loss 0.6940\n",
            "Train: epoch 0003 / 0030 | batch 0021 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0022 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0023 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0024 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0025 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0026 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0027 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0028 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0029 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0030 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0031 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0032 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0033 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0034 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0035 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0036 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0037 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0038 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0039 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0040 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0041 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0042 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0043 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0044 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0045 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0046 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0047 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0048 / 0050 | loss 0.6939\n",
            "Train: epoch 0003 / 0030 | batch 0049 / 0050 | loss 0.6939\n",
            "Val loss 0.0702\n",
            "Dice score : 16.5219669342041\n",
            "Val loss 0.0849\n",
            "Dice score : 70.0262680053711\n",
            "Val loss 0.0816\n",
            "Dice score : 30.242237091064453\n",
            "Val loss 0.0727\n",
            "Dice score : 65.23519134521484\n",
            "Val loss 0.0695\n",
            "Dice score : 67.54295349121094\n",
            "Val loss 0.0722\n",
            "Dice score : 89.23258209228516\n",
            "Val loss 0.0740\n",
            "Dice score : 74.69015502929688\n",
            "Val loss 0.0741\n",
            "Dice score : 98.92041778564453\n",
            "Val loss 0.0734\n",
            "Dice score : 98.83353424072266\n",
            "Val loss 0.0732\n",
            "Dice score : 102.97464752197266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 3/30 [03:51<34:51, 77.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0004 / 0030 | batch 0000 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0001 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0002 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0003 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0004 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0005 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0006 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0007 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0008 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0009 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0010 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0011 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0012 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0013 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0014 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0015 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0016 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0017 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0018 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0019 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0020 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0021 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0022 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0023 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0024 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0025 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0026 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0027 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0028 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0029 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0030 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0031 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0032 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0033 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0034 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0035 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0036 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0037 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0038 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0039 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0040 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0041 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0042 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0043 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0044 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0045 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0046 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0047 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0048 / 0050 | loss 0.6938\n",
            "Train: epoch 0004 / 0030 | batch 0049 / 0050 | loss 0.6938\n",
            "Val loss 0.0769\n",
            "Dice score : 5.5948896408081055\n",
            "Val loss 0.0671\n",
            "Dice score : 15.816868782043457\n",
            "Val loss 0.0660\n",
            "Dice score : 20.273839950561523\n",
            "Val loss 0.0686\n",
            "Dice score : 21.85232925415039\n",
            "Val loss 0.0701\n",
            "Dice score : 26.600173950195312\n",
            "Val loss 0.0665\n",
            "Dice score : 25.916568756103516\n",
            "Val loss 0.0716\n",
            "Dice score : 35.38869857788086\n",
            "Val loss 0.0734\n",
            "Dice score : 45.380104064941406\n",
            "Val loss 0.0719\n",
            "Dice score : 74.29903411865234\n",
            "Val loss 0.0750\n",
            "Dice score : 235.1739044189453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 4/30 [05:08<33:28, 77.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0005 / 0030 | batch 0000 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0001 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0002 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0003 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0004 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0005 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0006 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0007 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0008 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0009 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0010 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0011 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0012 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0013 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0014 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0015 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0016 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0017 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0018 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0019 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0020 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0021 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0022 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0023 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0024 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0025 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0026 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0027 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0028 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0029 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0030 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0031 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0032 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0033 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0034 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0035 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0036 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0037 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0038 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0039 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0040 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0041 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0042 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0043 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0044 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0045 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0046 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0047 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0048 / 0050 | loss 0.6937\n",
            "Train: epoch 0005 / 0030 | batch 0049 / 0050 | loss 0.6937\n",
            "Val loss 0.0611\n",
            "Dice score : 4.887873649597168\n",
            "Val loss 0.0628\n",
            "Dice score : 14.19795036315918\n",
            "Val loss 0.0665\n",
            "Dice score : 18.603036880493164\n",
            "Val loss 0.0647\n",
            "Dice score : 24.924793243408203\n",
            "Val loss 0.0627\n",
            "Dice score : 31.074920654296875\n",
            "Val loss 0.0660\n",
            "Dice score : 46.71630096435547\n",
            "Val loss 0.0698\n",
            "Dice score : 39.758060455322266\n",
            "Val loss 0.0747\n",
            "Dice score : 85.65677642822266\n",
            "Val loss 0.0760\n",
            "Dice score : 97.98283386230469\n",
            "Val loss 0.0767\n",
            "Dice score : 70.87883758544922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 5/30 [06:25<32:08, 77.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0006 / 0030 | batch 0000 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0001 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0002 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0003 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0004 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0005 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0006 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0007 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0008 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0009 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0010 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0011 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0012 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0013 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0014 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0015 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0016 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0017 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0018 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0019 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0020 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0021 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0022 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0023 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0024 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0025 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0026 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0027 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0028 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0029 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0030 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0031 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0032 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0033 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0034 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0035 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0036 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0037 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0038 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0039 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0040 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0041 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0042 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0043 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0044 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0045 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0046 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0047 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0048 / 0050 | loss 0.6936\n",
            "Train: epoch 0006 / 0030 | batch 0049 / 0050 | loss 0.6936\n",
            "Val loss 0.0599\n",
            "Dice score : 7.829482555389404\n",
            "Val loss 0.0740\n",
            "Dice score : 15.134994506835938\n",
            "Val loss 0.0717\n",
            "Dice score : 19.979751586914062\n",
            "Val loss 0.0897\n",
            "Dice score : 33.618167877197266\n",
            "Val loss 0.0859\n",
            "Dice score : 64.63484954833984\n",
            "Val loss 0.0834\n",
            "Dice score : 53.09706115722656\n",
            "Val loss 0.0807\n",
            "Dice score : 78.67498779296875\n",
            "Val loss 0.0784\n",
            "Dice score : 57.854713439941406\n",
            "Val loss 0.0782\n",
            "Dice score : 84.72984313964844\n",
            "Val loss 0.0785\n",
            "Dice score : 90.68704986572266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 6/30 [07:43<30:58, 77.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0007 / 0030 | batch 0000 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0001 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0002 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0003 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0004 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0005 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0006 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0007 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0008 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0009 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0010 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0011 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0012 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0013 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0014 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0015 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0016 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0017 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0018 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0019 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0020 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0021 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0022 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0023 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0024 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0025 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0026 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0027 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0028 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0029 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0030 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0031 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0032 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0033 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0034 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0035 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0036 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0037 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0038 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0039 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0040 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0041 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0042 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0043 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0044 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0045 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0046 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0047 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0048 / 0050 | loss 0.6935\n",
            "Train: epoch 0007 / 0030 | batch 0049 / 0050 | loss 0.6935\n",
            "Val loss 0.0752\n",
            "Dice score : 7.260334491729736\n",
            "Val loss 0.0630\n",
            "Dice score : 21.662803649902344\n",
            "Val loss 0.0754\n",
            "Dice score : 62.598976135253906\n",
            "Val loss 0.0765\n",
            "Dice score : 28.699331283569336\n",
            "Val loss 0.0737\n",
            "Dice score : 60.1070442199707\n",
            "Val loss 0.0750\n",
            "Dice score : 58.27336502075195\n",
            "Val loss 0.0772\n",
            "Dice score : 61.96834182739258\n",
            "Val loss 0.0768\n",
            "Dice score : 142.75106811523438\n",
            "Val loss 0.0753\n",
            "Dice score : 142.61500549316406\n",
            "Val loss 0.0798\n",
            "Dice score : 151.12791442871094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 7/30 [09:02<29:49, 77.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0008 / 0030 | batch 0000 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0001 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0002 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0003 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0004 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0005 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0006 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0007 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0008 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0009 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0010 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0011 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0012 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0013 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0014 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0015 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0016 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0017 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0018 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0019 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0020 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0021 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0022 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0023 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0024 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0025 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0026 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0027 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0028 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0029 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0030 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0031 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0032 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0033 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0034 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0035 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0036 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0037 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0038 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0039 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0040 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0041 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0042 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0043 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0044 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0045 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0046 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0047 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0048 / 0050 | loss 0.6935\n",
            "Train: epoch 0008 / 0030 | batch 0049 / 0050 | loss 0.6935\n",
            "Val loss 0.0619\n",
            "Dice score : 18.457500457763672\n",
            "Val loss 0.0810\n",
            "Dice score : 14.461254119873047\n",
            "Val loss 0.0767\n",
            "Dice score : 19.128677368164062\n",
            "Val loss 0.0852\n",
            "Dice score : 59.29547119140625\n",
            "Val loss 0.0815\n",
            "Dice score : 42.946224212646484\n",
            "Val loss 0.0821\n",
            "Dice score : 26.09593391418457\n",
            "Val loss 0.0862\n",
            "Dice score : 85.98280334472656\n",
            "Val loss 0.0828\n",
            "Dice score : 126.26252746582031\n",
            "Val loss 0.0813\n",
            "Dice score : 105.05907440185547\n",
            "Val loss 0.0813\n",
            "Dice score : 93.19322204589844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 8/30 [10:20<28:31, 77.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0009 / 0030 | batch 0000 / 0050 | loss 0.6935\n",
            "Train: epoch 0009 / 0030 | batch 0001 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0002 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0003 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0004 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0005 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0006 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0007 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0008 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0009 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0010 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0011 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0012 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0013 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0014 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0015 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0016 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0017 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0018 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0019 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0020 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0021 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0022 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0023 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0024 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0025 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0026 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0027 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0028 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0029 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0030 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0031 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0032 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0033 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0034 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0035 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0036 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0037 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0038 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0039 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0040 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0041 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0042 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0043 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0044 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0045 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0046 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0047 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0048 / 0050 | loss 0.6934\n",
            "Train: epoch 0009 / 0030 | batch 0049 / 0050 | loss 0.6934\n",
            "Val loss 0.0677\n",
            "Dice score : 25.146804809570312\n",
            "Val loss 0.0914\n",
            "Dice score : 42.22737121582031\n",
            "Val loss 0.1016\n",
            "Dice score : 61.46784591674805\n",
            "Val loss 0.0946\n",
            "Dice score : 89.78446197509766\n",
            "Val loss 0.0862\n",
            "Dice score : 142.93319702148438\n",
            "Val loss 0.0866\n",
            "Dice score : 174.27354431152344\n",
            "Val loss 0.0831\n",
            "Dice score : 108.61964416503906\n",
            "Val loss 0.0806\n",
            "Dice score : 233.60499572753906\n",
            "Val loss 0.0839\n",
            "Dice score : 193.7831268310547\n",
            "Val loss 0.0827\n",
            "Dice score : 255.47581481933594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 9/30 [11:37<27:13, 77.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0010 / 0030 | batch 0000 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0001 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0002 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0003 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0004 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0005 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0006 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0007 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0008 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0009 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0010 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0011 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0012 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0013 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0014 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0015 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0016 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0017 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0018 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0019 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0020 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0021 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0022 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0023 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0024 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0025 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0026 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0027 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0028 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0029 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0030 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0031 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0032 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0033 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0034 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0035 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0036 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0037 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0038 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0039 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0040 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0041 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0042 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0043 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0044 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0045 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0046 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0047 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0048 / 0050 | loss 0.6934\n",
            "Train: epoch 0010 / 0030 | batch 0049 / 0050 | loss 0.6934\n",
            "Val loss 0.0957\n",
            "Dice score : 8.708074569702148\n",
            "Val loss 0.0983\n",
            "Dice score : 29.741640090942383\n",
            "Val loss 0.0906\n",
            "Dice score : 28.23293685913086\n",
            "Val loss 0.0855\n",
            "Dice score : 41.56262969970703\n",
            "Val loss 0.0917\n",
            "Dice score : 95.60045623779297\n",
            "Val loss 0.0876\n",
            "Dice score : 69.6754150390625\n",
            "Val loss 0.0885\n",
            "Dice score : 67.862060546875\n",
            "Val loss 0.0898\n",
            "Dice score : 50.30184555053711\n",
            "Val loss 0.0859\n",
            "Dice score : 158.61573791503906\n",
            "Val loss 0.0840\n",
            "Dice score : 99.55266571044922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 10/30 [12:56<26:01, 78.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0011 / 0030 | batch 0000 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0001 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0002 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0003 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0004 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0005 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0006 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0007 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0008 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0009 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0010 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0011 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0012 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0013 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0014 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0015 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0016 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0017 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0018 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0019 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0020 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0021 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0022 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0023 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0024 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0025 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0026 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0027 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0028 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0029 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0030 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0031 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0032 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0033 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0034 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0035 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0036 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0037 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0038 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0039 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0040 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0041 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0042 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0043 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0044 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0045 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0046 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0047 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0048 / 0050 | loss 0.6934\n",
            "Train: epoch 0011 / 0030 | batch 0049 / 0050 | loss 0.6934\n",
            "Val loss 0.1019\n",
            "Dice score : 5.635691165924072\n",
            "Val loss 0.0942\n",
            "Dice score : 12.553165435791016\n",
            "Val loss 0.0865\n",
            "Dice score : 12.396831512451172\n",
            "Val loss 0.0815\n",
            "Dice score : 37.83292007446289\n",
            "Val loss 0.0812\n",
            "Dice score : 89.03914642333984\n",
            "Val loss 0.0840\n",
            "Dice score : 31.698862075805664\n",
            "Val loss 0.0818\n",
            "Dice score : 35.334537506103516\n",
            "Val loss 0.0799\n",
            "Dice score : 217.88043212890625\n",
            "Val loss 0.0770\n",
            "Dice score : 137.1095733642578\n",
            "Val loss 0.0848\n",
            "Dice score : 52.18087387084961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 11/30 [14:14<24:41, 77.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0012 / 0030 | batch 0000 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0001 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0002 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0003 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0004 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0005 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0006 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0007 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0008 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0009 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0010 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0011 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0012 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0013 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0014 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0015 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0016 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0017 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0018 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0019 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0020 / 0050 | loss 0.6934\n",
            "Train: epoch 0012 / 0030 | batch 0021 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0022 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0023 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0024 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0025 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0026 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0027 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0028 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0029 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0030 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0031 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0032 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0033 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0034 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0035 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0036 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0037 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0038 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0039 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0040 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0041 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0042 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0043 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0044 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0045 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0046 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0047 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0048 / 0050 | loss 0.6933\n",
            "Train: epoch 0012 / 0030 | batch 0049 / 0050 | loss 0.6933\n",
            "Val loss 0.0759\n",
            "Dice score : 22.211700439453125\n",
            "Val loss 0.0717\n",
            "Dice score : 72.2406234741211\n",
            "Val loss 0.0825\n",
            "Dice score : 47.75599670410156\n",
            "Val loss 0.0877\n",
            "Dice score : 135.61526489257812\n",
            "Val loss 0.0839\n",
            "Dice score : 133.64645385742188\n",
            "Val loss 0.0922\n",
            "Dice score : 108.66313934326172\n",
            "Val loss 0.0878\n",
            "Dice score : 332.7186279296875\n",
            "Val loss 0.0904\n",
            "Dice score : 141.66929626464844\n",
            "Val loss 0.0885\n",
            "Dice score : 139.384521484375\n",
            "Val loss 0.0862\n",
            "Dice score : 269.44598388671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 12/30 [15:33<23:31, 78.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0013 / 0030 | batch 0000 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0001 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0002 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0003 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0004 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0005 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0006 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0007 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0008 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0009 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0010 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0011 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0012 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0013 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0014 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0015 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0016 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0017 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0018 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0019 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0020 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0021 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0022 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0023 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0024 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0025 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0026 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0027 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0028 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0029 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0030 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0031 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0032 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0033 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0034 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0035 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0036 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0037 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0038 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0039 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0040 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0041 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0042 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0043 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0044 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0045 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0046 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0047 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0048 / 0050 | loss 0.6933\n",
            "Train: epoch 0013 / 0030 | batch 0049 / 0050 | loss 0.6933\n",
            "Val loss 0.0673\n",
            "Dice score : 19.10443687438965\n",
            "Val loss 0.0656\n",
            "Dice score : 49.6398811340332\n",
            "Val loss 0.0840\n",
            "Dice score : 84.30200958251953\n",
            "Val loss 0.0814\n",
            "Dice score : 65.72801971435547\n",
            "Val loss 0.0795\n",
            "Dice score : 108.90936279296875\n",
            "Val loss 0.0839\n",
            "Dice score : 85.94281768798828\n",
            "Val loss 0.0797\n",
            "Dice score : 130.5188446044922\n",
            "Val loss 0.0856\n",
            "Dice score : 185.9678192138672\n",
            "Val loss 0.0876\n",
            "Dice score : 173.42613220214844\n",
            "Val loss 0.0875\n",
            "Dice score : 150.2474822998047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 13/30 [16:52<22:15, 78.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0014 / 0030 | batch 0000 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0001 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0002 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0003 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0004 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0005 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0006 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0007 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0008 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0009 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0010 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0011 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0012 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0013 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0014 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0015 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0016 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0017 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0018 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0019 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0020 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0021 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0022 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0023 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0024 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0025 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0026 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0027 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0028 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0029 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0030 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0031 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0032 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0033 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0034 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0035 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0036 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0037 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0038 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0039 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0040 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0041 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0042 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0043 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0044 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0045 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0046 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0047 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0048 / 0050 | loss 0.6933\n",
            "Train: epoch 0014 / 0030 | batch 0049 / 0050 | loss 0.6933\n",
            "Val loss 0.1206\n",
            "Dice score : 19.566152572631836\n",
            "Val loss 0.0986\n",
            "Dice score : 24.90430450439453\n",
            "Val loss 0.0956\n",
            "Dice score : 34.861976623535156\n",
            "Val loss 0.0990\n",
            "Dice score : 44.47722625732422\n",
            "Val loss 0.0921\n",
            "Dice score : 87.11353302001953\n",
            "Val loss 0.0919\n",
            "Dice score : 99.32508087158203\n",
            "Val loss 0.0877\n",
            "Dice score : 46.16403579711914\n",
            "Val loss 0.0898\n",
            "Dice score : 133.46604919433594\n",
            "Val loss 0.0886\n",
            "Dice score : 171.46051025390625\n",
            "Val loss 0.0884\n",
            "Dice score : 149.6145477294922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 14/30 [18:10<20:50, 78.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0015 / 0030 | batch 0000 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0001 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0002 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0003 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0004 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0005 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0006 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0007 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0008 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0009 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0010 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0011 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0012 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0013 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0014 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0015 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0016 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0017 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0018 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0019 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0020 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0021 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0022 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0023 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0024 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0025 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0026 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0027 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0028 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0029 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0030 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0031 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0032 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0033 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0034 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0035 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0036 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0037 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0038 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0039 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0040 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0041 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0042 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0043 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0044 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0045 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0046 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0047 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0048 / 0050 | loss 0.6933\n",
            "Train: epoch 0015 / 0030 | batch 0049 / 0050 | loss 0.6933\n",
            "Val loss 0.0838\n",
            "Dice score : 14.73487377166748\n",
            "Val loss 0.0758\n",
            "Dice score : 35.633541107177734\n",
            "Val loss 0.0819\n",
            "Dice score : 44.58689880371094\n",
            "Val loss 0.0784\n",
            "Dice score : 112.5763168334961\n",
            "Val loss 0.0804\n",
            "Dice score : 105.5130615234375\n",
            "Val loss 0.0873\n",
            "Dice score : 91.24090576171875\n",
            "Val loss 0.0863\n",
            "Dice score : 78.68551635742188\n",
            "Val loss 0.0890\n",
            "Dice score : 201.2222137451172\n",
            "Val loss 0.0878\n",
            "Dice score : 195.282958984375\n",
            "Val loss 0.0893\n",
            "Dice score : 134.53346252441406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 15/30 [19:27<19:30, 78.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0016 / 0030 | batch 0000 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0001 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0002 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0003 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0004 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0005 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0006 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0007 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0008 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0009 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0010 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0011 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0012 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0013 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0014 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0015 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0016 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0017 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0018 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0019 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0020 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0021 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0022 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0023 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0024 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0025 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0026 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0027 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0028 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0029 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0030 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0031 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0032 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0033 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0034 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0035 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0036 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0037 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0038 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0039 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0040 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0041 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0042 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0043 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0044 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0045 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0046 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0047 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0048 / 0050 | loss 0.6933\n",
            "Train: epoch 0016 / 0030 | batch 0049 / 0050 | loss 0.6933\n",
            "Val loss 0.0742\n",
            "Dice score : 11.052023887634277\n",
            "Val loss 0.0835\n",
            "Dice score : 40.07284927368164\n",
            "Val loss 0.0952\n",
            "Dice score : 35.1143798828125\n",
            "Val loss 0.0970\n",
            "Dice score : 47.02125930786133\n",
            "Val loss 0.1003\n",
            "Dice score : 114.94642639160156\n",
            "Val loss 0.0942\n",
            "Dice score : 109.83837127685547\n",
            "Val loss 0.0899\n",
            "Dice score : 33.89744567871094\n",
            "Val loss 0.0887\n",
            "Dice score : 89.39873504638672\n",
            "Val loss 0.0927\n",
            "Dice score : 105.1277847290039\n",
            "Val loss 0.0903\n",
            "Dice score : 226.87704467773438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 16/30 [20:46<18:13, 78.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0017 / 0030 | batch 0000 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0001 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0002 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0003 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0004 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0005 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0006 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0007 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0008 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0009 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0010 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0011 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0012 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0013 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0014 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0015 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0016 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0017 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0018 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0019 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0020 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0021 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0022 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0023 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0024 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0025 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0026 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0027 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0028 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0029 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0030 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0031 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0032 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0033 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0034 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0035 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0036 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0037 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0038 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0039 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0040 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0041 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0042 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0043 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0044 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0045 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0046 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0047 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0048 / 0050 | loss 0.6933\n",
            "Train: epoch 0017 / 0030 | batch 0049 / 0050 | loss 0.6933\n",
            "Val loss 0.1102\n",
            "Dice score : 23.67854881286621\n",
            "Val loss 0.0939\n",
            "Dice score : 49.40394973754883\n",
            "Val loss 0.0850\n",
            "Dice score : 53.81168746948242\n",
            "Val loss 0.0816\n",
            "Dice score : 76.12602233886719\n",
            "Val loss 0.0797\n",
            "Dice score : 114.76921844482422\n",
            "Val loss 0.0788\n",
            "Dice score : 61.250301361083984\n",
            "Val loss 0.0861\n",
            "Dice score : 44.12540054321289\n",
            "Val loss 0.0875\n",
            "Dice score : 141.52618408203125\n",
            "Val loss 0.0918\n",
            "Dice score : 166.2201385498047\n",
            "Val loss 0.0914\n",
            "Dice score : 162.1331329345703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 17/30 [22:04<16:55, 78.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0018 / 0030 | batch 0000 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0001 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0002 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0003 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0004 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0005 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0006 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0007 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0008 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0009 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0010 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0011 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0012 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0013 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0014 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0015 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0016 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0017 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0018 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0019 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0020 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0021 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0022 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0023 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0024 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0025 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0026 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0027 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0028 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0029 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0030 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0031 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0032 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0033 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0034 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0035 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0036 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0037 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0038 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0039 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0040 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0041 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0042 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0043 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0044 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0045 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0046 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0047 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0048 / 0050 | loss 0.6933\n",
            "Train: epoch 0018 / 0030 | batch 0049 / 0050 | loss 0.6933\n",
            "Val loss 0.0843\n",
            "Dice score : 21.727455139160156\n",
            "Val loss 0.1070\n",
            "Dice score : 47.076805114746094\n",
            "Val loss 0.0954\n",
            "Dice score : 39.09633255004883\n",
            "Val loss 0.0923\n",
            "Dice score : 33.345611572265625\n",
            "Val loss 0.1004\n",
            "Dice score : 73.17118072509766\n",
            "Val loss 0.0967\n",
            "Dice score : 70.36117553710938\n",
            "Val loss 0.0912\n",
            "Dice score : 42.805721282958984\n",
            "Val loss 0.0880\n",
            "Dice score : 116.94583129882812\n",
            "Val loss 0.0911\n",
            "Dice score : 86.06511688232422\n",
            "Val loss 0.0920\n",
            "Dice score : 205.13926696777344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 18/30 [23:22<15:38, 78.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0019 / 0030 | batch 0000 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0001 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0002 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0003 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0004 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0005 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0006 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0007 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0008 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0009 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0010 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0011 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0012 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0013 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0014 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0015 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0016 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0017 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0018 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0019 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0020 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0021 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0022 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0023 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0024 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0025 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0026 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0027 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0028 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0029 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0030 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0031 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0032 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0033 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0034 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0035 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0036 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0037 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0038 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0039 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0040 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0041 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0042 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0043 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0044 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0045 / 0050 | loss 0.6933\n",
            "Train: epoch 0019 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0019 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0019 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0019 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.1435\n",
            "Dice score : 17.66063690185547\n",
            "Val loss 0.1242\n",
            "Dice score : 10.324666976928711\n",
            "Val loss 0.1153\n",
            "Dice score : 33.604454040527344\n",
            "Val loss 0.1034\n",
            "Dice score : 19.171520233154297\n",
            "Val loss 0.0964\n",
            "Dice score : 22.5014705657959\n",
            "Val loss 0.0998\n",
            "Dice score : 43.817081451416016\n",
            "Val loss 0.0956\n",
            "Dice score : 70.13420867919922\n",
            "Val loss 0.0929\n",
            "Dice score : 35.106056213378906\n",
            "Val loss 0.0921\n",
            "Dice score : 69.13270568847656\n",
            "Val loss 0.0926\n",
            "Dice score : 44.80528259277344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 19/30 [24:40<14:17, 77.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0020 / 0030 | batch 0000 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0001 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0002 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0003 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0004 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0005 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0006 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0007 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0008 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0009 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0010 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0011 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0012 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0013 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0014 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0015 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0016 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0017 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0018 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0019 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0020 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0021 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0022 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0023 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0024 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0025 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0026 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0027 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0028 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0029 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0030 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0031 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0032 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0033 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0034 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0035 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0036 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0037 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0038 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0039 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0040 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0041 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0042 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0043 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0044 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0045 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0020 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.1297\n",
            "Dice score : 16.344453811645508\n",
            "Val loss 0.1025\n",
            "Dice score : 20.83648681640625\n",
            "Val loss 0.0993\n",
            "Dice score : 18.974140167236328\n",
            "Val loss 0.1109\n",
            "Dice score : 23.74675941467285\n",
            "Val loss 0.1036\n",
            "Dice score : 65.56806945800781\n",
            "Val loss 0.1032\n",
            "Dice score : 37.52220916748047\n",
            "Val loss 0.0983\n",
            "Dice score : 44.084896087646484\n",
            "Val loss 0.0995\n",
            "Dice score : 90.7199478149414\n",
            "Val loss 0.0978\n",
            "Dice score : 108.25439453125\n",
            "Val loss 0.0939\n",
            "Dice score : 45.05724334716797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 20/30 [25:56<12:56, 77.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0021 / 0030 | batch 0000 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0001 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0002 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0003 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0004 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0005 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0006 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0007 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0008 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0009 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0010 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0011 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0012 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0013 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0014 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0015 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0016 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0017 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0018 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0019 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0020 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0021 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0022 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0023 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0024 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0025 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0026 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0027 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0028 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0029 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0030 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0031 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0032 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0033 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0034 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0035 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0036 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0037 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0038 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0039 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0040 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0041 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0042 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0043 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0044 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0045 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0021 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.1293\n",
            "Dice score : 25.030452728271484\n",
            "Val loss 0.1024\n",
            "Dice score : 22.15049934387207\n",
            "Val loss 0.0976\n",
            "Dice score : 16.301801681518555\n",
            "Val loss 0.0985\n",
            "Dice score : 20.918994903564453\n",
            "Val loss 0.0928\n",
            "Dice score : 39.2263298034668\n",
            "Val loss 0.0972\n",
            "Dice score : 173.16233825683594\n",
            "Val loss 0.0993\n",
            "Dice score : 42.084434509277344\n",
            "Val loss 0.0949\n",
            "Dice score : 37.01320266723633\n",
            "Val loss 0.0967\n",
            "Dice score : 84.9480209350586\n",
            "Val loss 0.0945\n",
            "Dice score : 100.1005630493164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 21/30 [27:13<11:35, 77.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0022 / 0030 | batch 0000 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0001 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0002 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0003 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0004 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0005 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0006 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0007 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0008 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0009 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0010 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0011 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0012 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0013 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0014 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0015 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0016 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0017 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0018 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0019 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0020 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0021 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0022 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0023 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0024 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0025 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0026 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0027 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0028 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0029 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0030 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0031 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0032 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0033 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0034 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0035 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0036 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0037 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0038 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0039 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0040 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0041 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0042 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0043 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0044 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0045 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0022 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.1165\n",
            "Dice score : 10.24405288696289\n",
            "Val loss 0.1041\n",
            "Dice score : 12.222593307495117\n",
            "Val loss 0.1077\n",
            "Dice score : 44.973045349121094\n",
            "Val loss 0.1134\n",
            "Dice score : 47.74972152709961\n",
            "Val loss 0.1046\n",
            "Dice score : 35.578086853027344\n",
            "Val loss 0.0998\n",
            "Dice score : 62.691585540771484\n",
            "Val loss 0.0989\n",
            "Dice score : 46.77204132080078\n",
            "Val loss 0.1012\n",
            "Dice score : 186.26025390625\n",
            "Val loss 0.0966\n",
            "Dice score : 168.2855682373047\n",
            "Val loss 0.0955\n",
            "Dice score : 111.53330993652344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 22/30 [28:30<10:19, 77.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0023 / 0030 | batch 0000 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0001 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0002 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0003 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0004 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0005 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0006 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0007 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0008 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0009 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0010 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0011 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0012 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0013 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0014 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0015 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0016 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0017 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0018 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0019 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0020 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0021 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0022 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0023 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0024 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0025 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0026 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0027 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0028 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0029 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0030 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0031 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0032 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0033 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0034 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0035 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0036 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0037 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0038 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0039 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0040 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0041 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0042 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0043 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0044 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0045 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0023 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.1218\n",
            "Dice score : 14.765316009521484\n",
            "Val loss 0.0989\n",
            "Dice score : 16.228254318237305\n",
            "Val loss 0.0888\n",
            "Dice score : 13.175774574279785\n",
            "Val loss 0.0998\n",
            "Dice score : 127.56012725830078\n",
            "Val loss 0.0947\n",
            "Dice score : 52.10536575317383\n",
            "Val loss 0.1046\n",
            "Dice score : 38.9998779296875\n",
            "Val loss 0.1001\n",
            "Dice score : 88.11531066894531\n",
            "Val loss 0.0973\n",
            "Dice score : 97.37506103515625\n",
            "Val loss 0.0972\n",
            "Dice score : 75.32050323486328\n",
            "Val loss 0.0963\n",
            "Dice score : 74.62057495117188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 23/30 [29:49<09:03, 77.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0024 / 0030 | batch 0000 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0001 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0002 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0003 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0004 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0005 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0006 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0007 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0008 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0009 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0010 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0011 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0012 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0013 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0014 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0015 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0016 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0017 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0018 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0019 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0020 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0021 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0022 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0023 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0024 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0025 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0026 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0027 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0028 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0029 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0030 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0031 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0032 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0033 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0034 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0035 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0036 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0037 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0038 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0039 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0040 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0041 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0042 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0043 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0044 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0045 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0024 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.0709\n",
            "Dice score : 25.034025192260742\n",
            "Val loss 0.0766\n",
            "Dice score : 32.99852752685547\n",
            "Val loss 0.0892\n",
            "Dice score : 57.67713165283203\n",
            "Val loss 0.0914\n",
            "Dice score : 46.424583435058594\n",
            "Val loss 0.0964\n",
            "Dice score : 72.2064437866211\n",
            "Val loss 0.1046\n",
            "Dice score : 104.29804992675781\n",
            "Val loss 0.1023\n",
            "Dice score : 120.98271942138672\n",
            "Val loss 0.0988\n",
            "Dice score : 180.15530395507812\n",
            "Val loss 0.1001\n",
            "Dice score : 134.41966247558594\n",
            "Val loss 0.0969\n",
            "Dice score : 134.3707733154297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 24/30 [31:06<07:46, 77.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0025 / 0030 | batch 0000 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0001 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0002 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0003 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0004 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0005 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0006 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0007 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0008 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0009 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0010 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0011 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0012 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0013 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0014 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0015 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0016 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0017 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0018 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0019 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0020 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0021 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0022 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0023 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0024 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0025 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0026 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0027 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0028 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0029 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0030 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0031 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0032 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0033 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0034 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0035 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0036 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0037 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0038 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0039 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0040 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0041 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0042 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0043 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0044 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0045 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0025 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.0661\n",
            "Dice score : 7.140413761138916\n",
            "Val loss 0.0812\n",
            "Dice score : 34.619808197021484\n",
            "Val loss 0.0845\n",
            "Dice score : 86.01512145996094\n",
            "Val loss 0.0860\n",
            "Dice score : 151.30564880371094\n",
            "Val loss 0.0853\n",
            "Dice score : 162.19281005859375\n",
            "Val loss 0.0936\n",
            "Dice score : 167.8654327392578\n",
            "Val loss 0.1009\n",
            "Dice score : 158.53402709960938\n",
            "Val loss 0.1021\n",
            "Dice score : 210.2387237548828\n",
            "Val loss 0.0987\n",
            "Dice score : 314.4310302734375\n",
            "Val loss 0.0981\n",
            "Dice score : 228.9428253173828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 25/30 [32:26<06:30, 78.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0026 / 0030 | batch 0000 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0001 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0002 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0003 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0004 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0005 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0006 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0007 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0008 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0009 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0010 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0011 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0012 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0013 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0014 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0015 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0016 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0017 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0018 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0019 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0020 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0021 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0022 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0023 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0024 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0025 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0026 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0027 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0028 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0029 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0030 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0031 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0032 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0033 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0034 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0035 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0036 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0037 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0038 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0039 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0040 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0041 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0042 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0043 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0044 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0045 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0026 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.0699\n",
            "Dice score : 30.63656997680664\n",
            "Val loss 0.1121\n",
            "Dice score : 25.31519889831543\n",
            "Val loss 0.1143\n",
            "Dice score : 36.28531265258789\n",
            "Val loss 0.1024\n",
            "Dice score : 47.82255554199219\n",
            "Val loss 0.1088\n",
            "Dice score : 48.532928466796875\n",
            "Val loss 0.1075\n",
            "Dice score : 105.6506118774414\n",
            "Val loss 0.1041\n",
            "Dice score : 69.11112213134766\n",
            "Val loss 0.1008\n",
            "Dice score : 95.97313690185547\n",
            "Val loss 0.0989\n",
            "Dice score : 84.65433502197266\n",
            "Val loss 0.0984\n",
            "Dice score : 279.7903747558594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 26/30 [33:43<05:11, 77.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0027 / 0030 | batch 0000 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0001 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0002 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0003 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0004 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0005 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0006 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0007 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0008 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0009 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0010 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0011 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0012 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0013 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0014 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0015 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0016 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0017 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0018 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0019 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0020 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0021 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0022 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0023 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0024 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0025 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0026 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0027 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0028 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0029 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0030 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0031 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0032 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0033 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0034 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0035 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0036 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0037 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0038 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0039 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0040 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0041 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0042 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0043 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0044 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0045 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0027 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.0702\n",
            "Dice score : 7.27003812789917\n",
            "Val loss 0.0719\n",
            "Dice score : 19.871944427490234\n",
            "Val loss 0.0952\n",
            "Dice score : 26.240699768066406\n",
            "Val loss 0.0958\n",
            "Dice score : 22.289255142211914\n",
            "Val loss 0.0922\n",
            "Dice score : 46.29224395751953\n",
            "Val loss 0.0933\n",
            "Dice score : 104.11715698242188\n",
            "Val loss 0.0974\n",
            "Dice score : 66.55990600585938\n",
            "Val loss 0.1012\n",
            "Dice score : 35.32830810546875\n",
            "Val loss 0.1018\n",
            "Dice score : 62.574790954589844\n",
            "Val loss 0.0994\n",
            "Dice score : 257.7481384277344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 27/30 [35:02<03:54, 78.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0028 / 0030 | batch 0000 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0001 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0002 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0003 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0004 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0005 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0006 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0007 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0008 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0009 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0010 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0011 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0012 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0013 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0014 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0015 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0016 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0017 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0018 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0019 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0020 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0021 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0022 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0023 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0024 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0025 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0026 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0027 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0028 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0029 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0030 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0031 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0032 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0033 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0034 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0035 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0036 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0037 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0038 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0039 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0040 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0041 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0042 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0043 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0044 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0045 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0028 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.0976\n",
            "Dice score : 46.08684539794922\n",
            "Val loss 0.1286\n",
            "Dice score : 61.21086502075195\n",
            "Val loss 0.1237\n",
            "Dice score : 126.04513549804688\n",
            "Val loss 0.1106\n",
            "Dice score : 35.929874420166016\n",
            "Val loss 0.1044\n",
            "Dice score : 161.5016326904297\n",
            "Val loss 0.1067\n",
            "Dice score : 160.4403076171875\n",
            "Val loss 0.1015\n",
            "Dice score : 255.42140197753906\n",
            "Val loss 0.0986\n",
            "Dice score : 439.5841979980469\n",
            "Val loss 0.0980\n",
            "Dice score : 258.5660705566406\n",
            "Val loss 0.1001\n",
            "Dice score : 465.143310546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 28/30 [36:21<02:36, 78.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0029 / 0030 | batch 0000 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0001 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0002 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0003 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0004 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0005 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0006 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0007 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0008 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0009 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0010 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0011 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0012 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0013 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0014 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0015 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0016 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0017 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0018 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0019 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0020 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0021 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0022 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0023 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0024 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0025 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0026 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0027 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0028 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0029 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0030 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0031 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0032 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0033 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0034 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0035 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0036 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0037 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0038 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0039 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0040 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0041 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0042 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0043 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0044 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0045 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0029 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.0712\n",
            "Dice score : 15.669999122619629\n",
            "Val loss 0.1084\n",
            "Dice score : 37.74687194824219\n",
            "Val loss 0.0998\n",
            "Dice score : 67.87870025634766\n",
            "Val loss 0.0979\n",
            "Dice score : 32.53848648071289\n",
            "Val loss 0.0909\n",
            "Dice score : 139.14852905273438\n",
            "Val loss 0.0940\n",
            "Dice score : 95.01787567138672\n",
            "Val loss 0.0923\n",
            "Dice score : 81.90338897705078\n",
            "Val loss 0.0958\n",
            "Dice score : 325.62835693359375\n",
            "Val loss 0.0971\n",
            "Dice score : 160.3444061279297\n",
            "Val loss 0.1008\n",
            "Dice score : 199.12677001953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 29/30 [37:38<01:18, 78.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: epoch 0030 / 0030 | batch 0000 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0001 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0002 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0003 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0004 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0005 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0006 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0007 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0008 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0009 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0010 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0011 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0012 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0013 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0014 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0015 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0016 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0017 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0018 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0019 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0020 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0021 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0022 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0023 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0024 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0025 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0026 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0027 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0028 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0029 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0030 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0031 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0032 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0033 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0034 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0035 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0036 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0037 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0038 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0039 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0040 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0041 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0042 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0043 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0044 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0045 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0046 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0047 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0048 / 0050 | loss 0.6932\n",
            "Train: epoch 0030 / 0030 | batch 0049 / 0050 | loss 0.6932\n",
            "Val loss 0.1229\n",
            "Dice score : 15.545646667480469\n",
            "Val loss 0.0997\n",
            "Dice score : 16.82221794128418\n",
            "Val loss 0.0996\n",
            "Dice score : 33.82204055786133\n",
            "Val loss 0.0926\n",
            "Dice score : 57.321922302246094\n",
            "Val loss 0.0996\n",
            "Dice score : 84.80636596679688\n",
            "Val loss 0.1111\n",
            "Dice score : 149.97474670410156\n",
            "Val loss 0.1050\n",
            "Dice score : 83.23594665527344\n",
            "Val loss 0.1038\n",
            "Dice score : 90.09170532226562\n",
            "Val loss 0.1027\n",
            "Dice score : 126.55470275878906\n",
            "Val loss 0.1013\n",
            "Dice score : 281.0013122558594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [38:55<00:00, 77.85s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Dataset(data_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/test' , transform = transform_testset)\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers = 8)\n",
        "\n",
        "train_trainer_Spine_segment.test(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VxLcxWhtU7o",
        "outputId": "e6be96cb-4149-4aff-d7d0-17894ca5167a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['151.dcm', '152.dcm', '153.dcm', '154.dcm', '155.dcm', '156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3052, 2140)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(3052, 2140, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['152.dcm', '153.dcm', '154.dcm', '155.dcm', '156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3264, 1852)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(3264, 1852, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['153.dcm', '154.dcm', '155.dcm', '156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3228, 1616)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(3228, 1616, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['154.dcm', '155.dcm', '156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3228, 1816)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(3228, 1816, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['155.dcm', '156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3228, 1800)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(3228, 1800, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3264, 1672)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(3264, 1672, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3264, 1964)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(3264, 1964, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3036, 3076)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(3036, 3076, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3112, 2108)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(3112, 2108, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3264, 2140)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(3264, 2140, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2680, 1460)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(2680, 1460, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2716, 1628)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(2716, 1628, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2712, 1992)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(2712, 1992, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2736, 1324)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(2736, 1324, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2832, 2520)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(2832, 2520, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2852, 1800)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(2852, 1800, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2496, 1172)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(2496, 1172, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2748, 1340)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(2748, 1340, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['189.dcm', '190.dcm']\n",
            "(1, 2560, 1280)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(2560, 1280, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['190.dcm']\n",
            "(1, 2760, 1972)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "(2760, 1972, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "eFrTXt-0qsTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Dataset(data_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/test' , transform = transform_testset)\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers = 8)"
      ],
      "metadata": {
        "id": "f81Uv1nEqu1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_Spine_segment.test(test_loader)"
      ],
      "metadata": {
        "id": "EzoVOllkql8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# checkpoint load to model"
      ],
      "metadata": {
        "id": "VNXG42c7jlt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = Dataset(data_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/test')\n",
        "\n",
        "# print(example.lst_input)\n",
        "# for name in example.lst_input:\n",
        "#     print(name[:-3])\n",
        "#     break\n",
        "# print(example.lst_input.pop(0)[:-3])\n",
        "# for i in range(20):\n",
        "#   data = example.__getitem__(i)\n",
        "#   input = data['input']\n",
        "#   print(input.shape)\n",
        "\n",
        "a =np.load('/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/leaderboard/155.npy')\n",
        "print(a.shape[0]*a.shape[1])\n",
        "print(a[:,:,6].sum())\n",
        "print(type(a[0,0,0]))\n",
        "plt.subplot(111)\n",
        "plt.imshow(a[:,:,6], cmap='gray')\n",
        "plt.title('output')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "AxneApNA3mFw",
        "outputId": "d6cd36f6-80d9-4a92-8dcd-dd5ba2c593f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5810400\n",
            "782353\n",
            "<class 'numpy.uint8'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'output')"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이 셀 실행"
      ],
      "metadata": {
        "id": "0IMr_Q5cYsa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_net = UNET()\n",
        "test_net.cuda()\n",
        "\n",
        "optim = torch.optim.Adagrad(test_net.parameters(), lr = 0.01)\n",
        "test_net, optim, start_epoch = load(ckpt_dir = ckpt_dir, net = test_net, optim = optim) # 저장된 네트워크 불러오기\n",
        "\n",
        "test_trainer_Spine_segment = trainer(test_net, train_loader,\"Adagrad\", epoch_size=20, learning_rate=0.0001)\n",
        "\n",
        "test_trainer_Spine_segment.test(test_loader)"
      ],
      "metadata": {
        "id": "5dnQvvTPcaaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc72714c-edb5-4cf0-a106-4d2c23366d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['151.dcm', '152.dcm', '153.dcm', '154.dcm', '155.dcm', '156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3052, 2140)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(3052, 2140, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['152.dcm', '153.dcm', '154.dcm', '155.dcm', '156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3264, 1852)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(3264, 1852, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['153.dcm', '154.dcm', '155.dcm', '156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3228, 1616)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(3228, 1616, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['154.dcm', '155.dcm', '156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3228, 1816)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(3228, 1816, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['155.dcm', '156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3228, 1800)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(3228, 1800, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['156.dcm', '157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3264, 1672)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(3264, 1672, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['157.dcm', '158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3264, 1964)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(3264, 1964, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['158.dcm', '159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3036, 3076)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(3036, 3076, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['159.dcm', '160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3112, 2108)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(3112, 2108, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['160.dcm', '181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 3264, 2140)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(3264, 2140, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['181.dcm', '182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2680, 1460)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(2680, 1460, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['182.dcm', '183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2716, 1628)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(2716, 1628, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['183.dcm', '184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2712, 1992)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(2712, 1992, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['184.dcm', '185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2736, 1324)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(2736, 1324, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['185.dcm', '186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2832, 2520)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(2832, 2520, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['186.dcm', '187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2852, 1800)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(2852, 1800, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['187.dcm', '188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2496, 1172)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(2496, 1172, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['188.dcm', '189.dcm', '190.dcm']\n",
            "(1, 2748, 1340)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(2748, 1340, 7)\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['189.dcm', '190.dcm']\n",
            "(1, 2560, 1280)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(2560, 1280, 7)\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "['190.dcm']\n",
            "(1, 2760, 1972)\n",
            "torch.Size([2, 6, 1024, 1024])\n",
            "torch.Size([6, 1024, 1024])\n",
            "1.0\n",
            "(2760, 1972, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# After Train & Test : (Input & label & output) image file save and visualization"
      ],
      "metadata": {
        "id": "HbWS_gYCw4KH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = np.load('/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/result/numpy/output_0011.npy')\n",
        "\n",
        "# aaaaa = output[4]\n",
        "# print(aaaaa)\n",
        "# classifier = lambda x :  1.0 * (x > 0.5)\n",
        "# print(np.amin(aaaaa))\n",
        "# print(np.amax(aaaaa))\n",
        "\n",
        "# dn = lambda x, min : x - min\n",
        "# positive = dn(aaaaa, min=np.amin(aaaaa))\n",
        "# dnn =dn(output[3], max=np.amax(output[3]), min=np.amin(output[3]))\n",
        "\n",
        "\n",
        "# preds = (output-np.mean(aaaaa))/np.std(aaaaa)\n",
        "# preds = torch.sigmoid(preds)\n",
        "# preds = classifier(preds)\n",
        "\n",
        "\n",
        "print(output.shape)\n",
        "\n",
        "print(output)\n",
        "\n",
        "\n",
        "plt.subplot(161)\n",
        "plt.imshow(output[0], cmap='gray')\n",
        "plt.title('output')\n",
        "\n",
        "plt.subplot(162)\n",
        "plt.imshow(output[1], cmap='gray')\n",
        "plt.title('output')\n",
        "\n",
        "plt.subplot(163)\n",
        "plt.imshow(output[2], cmap='gray')\n",
        "plt.title('output')\n",
        "\n",
        "plt.subplot(164)\n",
        "plt.imshow(output[3], cmap='gray')\n",
        "plt.title('output')\n",
        "\n",
        "plt.subplot(165)\n",
        "plt.imshow(output[4], cmap='gray')\n",
        "plt.title('output')\n",
        "\n",
        "plt.subplot(166)\n",
        "plt.imshow(output[5], cmap='gray')\n",
        "plt.title('output')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BlfF46XpF0hp",
        "outputId": "5a118242-4711-4efc-e1af-a46bd5f157c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 1024, 1024)\n",
            "[[[1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 0. ... 0. 1. 1.]\n",
            "  [1. 1. 0. ... 0. 0. 1.]\n",
            "  ...\n",
            "  [0. 1. 0. ... 1. 1. 1.]\n",
            "  [1. 1. 0. ... 1. 1. 1.]\n",
            "  [0. 1. 1. ... 1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 0. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 0. 1.]\n",
            "  [0. 0. 0. ... 0. 0. 1.]\n",
            "  [1. 1. 0. ... 0. 0. 1.]\n",
            "  ...\n",
            "  [1. 0. 0. ... 1. 1. 1.]\n",
            "  [1. 0. 1. ... 1. 1. 1.]\n",
            "  [1. 1. 1. ... 1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1. ... 1. 1. 0.]\n",
            "  [0. 0. 0. ... 1. 1. 0.]\n",
            "  [1. 0. 0. ... 1. 1. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 1. 0. 0.]\n",
            "  [1. 1. 0. ... 1. 1. 0.]\n",
            "  [1. 1. 0. ... 1. 1. 1.]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'output')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.load('/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/result/numpy/input_0010.npy')\n",
        "output = np.load('/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/result/numpy/output_0010.npy')\n",
        "\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(input, cmap='gray')\n",
        "plt.title('input')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(output[0],cmap='gray')\n",
        "plt.title('output')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "vjZSU0U7hct8",
        "outputId": "ec62d2d6-087e-4ae7-8339-a870a154756b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'output')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_dir = '/content/drive/MyDrive/21-2/basic_ai/challenge/challenge_dataset/data/result'\n",
        "\n",
        "lst_data = os.listdir(result_dir)\n",
        "\n",
        "lst_input = [f for f in lst_data if f.startswith('input')]\n",
        "lst_label = [f for f in lst_data if f.startswith('label')]\n",
        "lst_output = [f for f in lst_data if f.startswith('output')]\n",
        "\n",
        "lst_input.sort()\n",
        "lst_label.sort()\n",
        "lst_output.sort()\n",
        "\n",
        "id=0\n",
        "\n",
        "input = np.load(os.path.join(result_dir, lst_input[id]))\n",
        "label = np.load(os.path.join(result_dir, lst_label[id]))\n",
        "output = np.load(os.path.join(result_dir, lst_output[id]))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.imshow(input, cmap='gray')\n",
        "plt.title('input')\n",
        "\n",
        "plt.subplot(132)\n",
        "plt.imshow(label,cmap='gray')\n",
        "plt.title('label')\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.imshow(result,cmap='gray')\n",
        "plt.title('result')"
      ],
      "metadata": {
        "id": "PVGsBUWlw-lF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "a6835569-2436-492f-cb9e-df7a6b00d127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-dd5931fca8ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2cHP5couS9iU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}